{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db19a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8101fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-01 20:53:45,450\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-06-01 20:53:45,639\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\gluonts\\json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasetsforecast.m3 import M3\n",
    "from utilsforecast.plotting import plot_series\n",
    "import pandas as pd\n",
    "from models.NBeatsStackMoe import NBeatsStackMoe\n",
    "from models.NBeatsMoeLags import NBeatsMoeLags\n",
    "from neuralforecast import NeuralForecast\n",
    "from utils import load_dataset, train_test_split\n",
    "from models.callbacks.probs_collector import GateValuesCollectorCallback\n",
    "from neuralforecast.losses.numpy import smape\n",
    "from neuralforecast.models import NBEATS\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets.load_data.gluonts_dataset import GluontsDataset\n",
    "from models.hyper import config\n",
    "import numpy as np\n",
    "import random\n",
    "from neuralforecast.losses.pytorch import HuberLoss, MAE, MSE, SMAPE, MAPE, MASE\n",
    "from functools import partial\n",
    "\n",
    "# Load the M3 dataset\n",
    "m3 = M3.load(directory='C:\\\\Users\\\\ricar\\\\mixture_of_experts_time_series\\\\data\\\\m3\\\\', group='Monthly')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680874da",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f2cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smape(Y_test_df, Y_hat_df, forecast_col):\n",
    "    \"\"\"Calculate the sMAPE.\"\"\"\n",
    "    y_true = Y_test_df['y'].values\n",
    "    try:\n",
    "        y_hat = Y_hat_df[forecast_col].values\n",
    "    except Exception as exc:\n",
    "        y_hat = Y_hat_df\n",
    "   \n",
    "    n_series = Y_test_df['unique_id'].nunique()\n",
    "    try:\n",
    "        y_true = y_true.reshape(n_series, -1)\n",
    "        y_hat = y_hat.reshape(n_series, -1)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Error reshaping arrays\") from e\n",
    "\n",
    "    return smape(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e86eb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-03-31</td>\n",
       "      <td>2280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-04-30</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-05-31</td>\n",
       "      <td>5040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-06-30</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-07-31</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-10-31</td>\n",
       "      <td>5225.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25700</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-11-30</td>\n",
       "      <td>5236.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25701</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-12-31</td>\n",
       "      <td>5186.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25702</th>\n",
       "      <td>M999</td>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>5143.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25703</th>\n",
       "      <td>M999</td>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>5152.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25704 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id         ds       y\n",
       "0            M1 1994-03-31  2280.0\n",
       "1            M1 1994-04-30   480.0\n",
       "2            M1 1994-05-31  5040.0\n",
       "3            M1 1994-06-30  1920.0\n",
       "4            M1 1994-07-31   840.0\n",
       "...         ...        ...     ...\n",
       "25699      M999 1993-10-31  5225.9\n",
       "25700      M999 1993-11-30  5236.3\n",
       "25701      M999 1993-12-31  5186.6\n",
       "25702      M999 1994-01-31  5143.4\n",
       "25703      M999 1994-02-28  5152.6\n",
       "\n",
       "[25704 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = train_test_split(m3, horizon)\n",
    "_t , y_val = train_test_split(y_train, horizon)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd80a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>NBeatsStackMoe</th>\n",
       "      <th>NBeatsStackMoe1</th>\n",
       "      <th>NBeatsStackMoe2</th>\n",
       "      <th>NBeatsStackMoe3</th>\n",
       "      <th>NBeatsStackMoe4</th>\n",
       "      <th>NBeatsStackMoe5</th>\n",
       "      <th>NBeatsStackMoe6</th>\n",
       "      <th>NBeatsStackMoe7</th>\n",
       "      <th>...</th>\n",
       "      <th>NBeatsStackMoe9</th>\n",
       "      <th>NBeatsStackMoe10</th>\n",
       "      <th>NBeatsStackMoe11</th>\n",
       "      <th>NBeatsStackMoe12</th>\n",
       "      <th>NBeatsStackMoe13</th>\n",
       "      <th>NBeatsStackMoe14</th>\n",
       "      <th>NBeatsStackMoe15</th>\n",
       "      <th>NBeatsStackMoe16</th>\n",
       "      <th>NBeatsStackMoe17</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1</td>\n",
       "      <td>1992-09-30</td>\n",
       "      <td>3963.7890</td>\n",
       "      <td>2658.6956</td>\n",
       "      <td>3268.8276</td>\n",
       "      <td>4374.0864</td>\n",
       "      <td>3285.8740</td>\n",
       "      <td>2740.3862</td>\n",
       "      <td>4332.7230</td>\n",
       "      <td>2626.1282</td>\n",
       "      <td>...</td>\n",
       "      <td>5545.0103</td>\n",
       "      <td>3911.6821</td>\n",
       "      <td>3141.7856</td>\n",
       "      <td>2391.0073</td>\n",
       "      <td>2424.4550</td>\n",
       "      <td>4278.0150</td>\n",
       "      <td>3383.3987</td>\n",
       "      <td>3502.9350</td>\n",
       "      <td>2824.3928</td>\n",
       "      <td>6720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>1992-10-31</td>\n",
       "      <td>5095.4526</td>\n",
       "      <td>3283.7500</td>\n",
       "      <td>3347.9390</td>\n",
       "      <td>3634.2030</td>\n",
       "      <td>3806.8594</td>\n",
       "      <td>2534.0990</td>\n",
       "      <td>4432.4550</td>\n",
       "      <td>3679.2720</td>\n",
       "      <td>...</td>\n",
       "      <td>4834.1123</td>\n",
       "      <td>4568.1045</td>\n",
       "      <td>4342.5110</td>\n",
       "      <td>2728.1008</td>\n",
       "      <td>2376.9482</td>\n",
       "      <td>4364.2046</td>\n",
       "      <td>3679.3070</td>\n",
       "      <td>3475.8918</td>\n",
       "      <td>3015.0650</td>\n",
       "      <td>2040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M1</td>\n",
       "      <td>1992-11-30</td>\n",
       "      <td>4936.2110</td>\n",
       "      <td>3554.6455</td>\n",
       "      <td>3771.4023</td>\n",
       "      <td>3931.0085</td>\n",
       "      <td>3188.3438</td>\n",
       "      <td>3709.8503</td>\n",
       "      <td>4892.7150</td>\n",
       "      <td>2763.7173</td>\n",
       "      <td>...</td>\n",
       "      <td>4671.7010</td>\n",
       "      <td>4570.1045</td>\n",
       "      <td>5816.4260</td>\n",
       "      <td>2230.4595</td>\n",
       "      <td>2559.6543</td>\n",
       "      <td>4336.2104</td>\n",
       "      <td>4923.6807</td>\n",
       "      <td>3172.8690</td>\n",
       "      <td>2901.2815</td>\n",
       "      <td>6480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1</td>\n",
       "      <td>1992-12-31</td>\n",
       "      <td>5008.3940</td>\n",
       "      <td>3131.2640</td>\n",
       "      <td>3643.9912</td>\n",
       "      <td>4377.4030</td>\n",
       "      <td>3148.4834</td>\n",
       "      <td>3053.1987</td>\n",
       "      <td>2716.7812</td>\n",
       "      <td>2297.1086</td>\n",
       "      <td>...</td>\n",
       "      <td>4741.8857</td>\n",
       "      <td>4085.8860</td>\n",
       "      <td>5320.5293</td>\n",
       "      <td>2480.0984</td>\n",
       "      <td>2457.8064</td>\n",
       "      <td>4447.3853</td>\n",
       "      <td>4327.8667</td>\n",
       "      <td>2590.8820</td>\n",
       "      <td>3013.7786</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M1</td>\n",
       "      <td>1993-01-31</td>\n",
       "      <td>3946.1968</td>\n",
       "      <td>3554.4758</td>\n",
       "      <td>3441.6270</td>\n",
       "      <td>3801.2024</td>\n",
       "      <td>2672.5230</td>\n",
       "      <td>2355.5620</td>\n",
       "      <td>2734.1277</td>\n",
       "      <td>3180.3503</td>\n",
       "      <td>...</td>\n",
       "      <td>4404.7275</td>\n",
       "      <td>4477.7170</td>\n",
       "      <td>4027.7810</td>\n",
       "      <td>3057.4010</td>\n",
       "      <td>2361.2397</td>\n",
       "      <td>3321.3594</td>\n",
       "      <td>3808.6404</td>\n",
       "      <td>4378.8345</td>\n",
       "      <td>2353.1252</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>M999</td>\n",
       "      <td>1992-04-30</td>\n",
       "      <td>5399.9434</td>\n",
       "      <td>5434.9106</td>\n",
       "      <td>5392.6180</td>\n",
       "      <td>5304.3880</td>\n",
       "      <td>5384.0693</td>\n",
       "      <td>5412.8440</td>\n",
       "      <td>5803.4600</td>\n",
       "      <td>5502.0340</td>\n",
       "      <td>...</td>\n",
       "      <td>5478.7017</td>\n",
       "      <td>5572.3867</td>\n",
       "      <td>5544.2420</td>\n",
       "      <td>5669.4985</td>\n",
       "      <td>5460.0260</td>\n",
       "      <td>5478.3990</td>\n",
       "      <td>5515.3247</td>\n",
       "      <td>5443.6210</td>\n",
       "      <td>5462.6990</td>\n",
       "      <td>5165.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25700</th>\n",
       "      <td>M999</td>\n",
       "      <td>1992-05-31</td>\n",
       "      <td>5412.2910</td>\n",
       "      <td>5427.0273</td>\n",
       "      <td>5404.3110</td>\n",
       "      <td>5296.0063</td>\n",
       "      <td>5413.8467</td>\n",
       "      <td>5415.9385</td>\n",
       "      <td>5741.4067</td>\n",
       "      <td>5531.2144</td>\n",
       "      <td>...</td>\n",
       "      <td>5449.4927</td>\n",
       "      <td>5618.0444</td>\n",
       "      <td>5607.4453</td>\n",
       "      <td>5676.3280</td>\n",
       "      <td>5452.0210</td>\n",
       "      <td>5483.4863</td>\n",
       "      <td>5533.8770</td>\n",
       "      <td>5462.8050</td>\n",
       "      <td>5489.7970</td>\n",
       "      <td>5182.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25701</th>\n",
       "      <td>M999</td>\n",
       "      <td>1992-06-30</td>\n",
       "      <td>5438.8500</td>\n",
       "      <td>5451.9224</td>\n",
       "      <td>5416.0073</td>\n",
       "      <td>5338.1206</td>\n",
       "      <td>5355.2570</td>\n",
       "      <td>5433.7188</td>\n",
       "      <td>5787.4434</td>\n",
       "      <td>5563.6910</td>\n",
       "      <td>...</td>\n",
       "      <td>5549.1120</td>\n",
       "      <td>5636.4100</td>\n",
       "      <td>5599.2744</td>\n",
       "      <td>5712.7110</td>\n",
       "      <td>5486.7075</td>\n",
       "      <td>5513.5347</td>\n",
       "      <td>5546.7812</td>\n",
       "      <td>5460.1030</td>\n",
       "      <td>5504.5620</td>\n",
       "      <td>5218.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25702</th>\n",
       "      <td>M999</td>\n",
       "      <td>1992-07-31</td>\n",
       "      <td>5459.8145</td>\n",
       "      <td>5480.2563</td>\n",
       "      <td>5435.8000</td>\n",
       "      <td>5363.6270</td>\n",
       "      <td>5456.9090</td>\n",
       "      <td>5442.9863</td>\n",
       "      <td>5829.7230</td>\n",
       "      <td>5584.6650</td>\n",
       "      <td>...</td>\n",
       "      <td>5576.1730</td>\n",
       "      <td>5657.7256</td>\n",
       "      <td>5615.5070</td>\n",
       "      <td>5730.6300</td>\n",
       "      <td>5508.9106</td>\n",
       "      <td>5523.8403</td>\n",
       "      <td>5574.6123</td>\n",
       "      <td>5567.0107</td>\n",
       "      <td>5528.2570</td>\n",
       "      <td>5261.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25703</th>\n",
       "      <td>M999</td>\n",
       "      <td>1992-08-31</td>\n",
       "      <td>5495.3750</td>\n",
       "      <td>5495.1390</td>\n",
       "      <td>5454.7940</td>\n",
       "      <td>5320.0225</td>\n",
       "      <td>5410.2030</td>\n",
       "      <td>5477.5770</td>\n",
       "      <td>5847.7246</td>\n",
       "      <td>5594.1540</td>\n",
       "      <td>...</td>\n",
       "      <td>5417.4010</td>\n",
       "      <td>5709.4620</td>\n",
       "      <td>5632.0030</td>\n",
       "      <td>5732.6020</td>\n",
       "      <td>5520.5503</td>\n",
       "      <td>5562.0610</td>\n",
       "      <td>5585.7515</td>\n",
       "      <td>5452.0740</td>\n",
       "      <td>5531.9140</td>\n",
       "      <td>5247.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25704 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id          ds  NBeatsStackMoe  NBeatsStackMoe1  NBeatsStackMoe2  \\\n",
       "0            M1  1992-09-30       3963.7890        2658.6956        3268.8276   \n",
       "1            M1  1992-10-31       5095.4526        3283.7500        3347.9390   \n",
       "2            M1  1992-11-30       4936.2110        3554.6455        3771.4023   \n",
       "3            M1  1992-12-31       5008.3940        3131.2640        3643.9912   \n",
       "4            M1  1993-01-31       3946.1968        3554.4758        3441.6270   \n",
       "...         ...         ...             ...              ...              ...   \n",
       "25699      M999  1992-04-30       5399.9434        5434.9106        5392.6180   \n",
       "25700      M999  1992-05-31       5412.2910        5427.0273        5404.3110   \n",
       "25701      M999  1992-06-30       5438.8500        5451.9224        5416.0073   \n",
       "25702      M999  1992-07-31       5459.8145        5480.2563        5435.8000   \n",
       "25703      M999  1992-08-31       5495.3750        5495.1390        5454.7940   \n",
       "\n",
       "       NBeatsStackMoe3  NBeatsStackMoe4  NBeatsStackMoe5  NBeatsStackMoe6  \\\n",
       "0            4374.0864        3285.8740        2740.3862        4332.7230   \n",
       "1            3634.2030        3806.8594        2534.0990        4432.4550   \n",
       "2            3931.0085        3188.3438        3709.8503        4892.7150   \n",
       "3            4377.4030        3148.4834        3053.1987        2716.7812   \n",
       "4            3801.2024        2672.5230        2355.5620        2734.1277   \n",
       "...                ...              ...              ...              ...   \n",
       "25699        5304.3880        5384.0693        5412.8440        5803.4600   \n",
       "25700        5296.0063        5413.8467        5415.9385        5741.4067   \n",
       "25701        5338.1206        5355.2570        5433.7188        5787.4434   \n",
       "25702        5363.6270        5456.9090        5442.9863        5829.7230   \n",
       "25703        5320.0225        5410.2030        5477.5770        5847.7246   \n",
       "\n",
       "       NBeatsStackMoe7  ...  NBeatsStackMoe9  NBeatsStackMoe10  \\\n",
       "0            2626.1282  ...        5545.0103         3911.6821   \n",
       "1            3679.2720  ...        4834.1123         4568.1045   \n",
       "2            2763.7173  ...        4671.7010         4570.1045   \n",
       "3            2297.1086  ...        4741.8857         4085.8860   \n",
       "4            3180.3503  ...        4404.7275         4477.7170   \n",
       "...                ...  ...              ...               ...   \n",
       "25699        5502.0340  ...        5478.7017         5572.3867   \n",
       "25700        5531.2144  ...        5449.4927         5618.0444   \n",
       "25701        5563.6910  ...        5549.1120         5636.4100   \n",
       "25702        5584.6650  ...        5576.1730         5657.7256   \n",
       "25703        5594.1540  ...        5417.4010         5709.4620   \n",
       "\n",
       "       NBeatsStackMoe11  NBeatsStackMoe12  NBeatsStackMoe13  NBeatsStackMoe14  \\\n",
       "0             3141.7856         2391.0073         2424.4550         4278.0150   \n",
       "1             4342.5110         2728.1008         2376.9482         4364.2046   \n",
       "2             5816.4260         2230.4595         2559.6543         4336.2104   \n",
       "3             5320.5293         2480.0984         2457.8064         4447.3853   \n",
       "4             4027.7810         3057.4010         2361.2397         3321.3594   \n",
       "...                 ...               ...               ...               ...   \n",
       "25699         5544.2420         5669.4985         5460.0260         5478.3990   \n",
       "25700         5607.4453         5676.3280         5452.0210         5483.4863   \n",
       "25701         5599.2744         5712.7110         5486.7075         5513.5347   \n",
       "25702         5615.5070         5730.6300         5508.9106         5523.8403   \n",
       "25703         5632.0030         5732.6020         5520.5503         5562.0610   \n",
       "\n",
       "       NBeatsStackMoe15  NBeatsStackMoe16  NBeatsStackMoe17       y  \n",
       "0             3383.3987         3502.9350         2824.3928  6720.0  \n",
       "1             3679.3070         3475.8918         3015.0650  2040.0  \n",
       "2             4923.6807         3172.8690         2901.2815  6480.0  \n",
       "3             4327.8667         2590.8820         3013.7786  1920.0  \n",
       "4             3808.6404         4378.8345         2353.1252  3600.0  \n",
       "...                 ...               ...               ...     ...  \n",
       "25699         5515.3247         5443.6210         5462.6990  5165.1  \n",
       "25700         5533.8770         5462.8050         5489.7970  5182.1  \n",
       "25701         5546.7812         5460.1030         5504.5620  5218.8  \n",
       "25702         5574.6123         5567.0107         5528.2570  5261.6  \n",
       "25703         5585.7515         5452.0740         5531.9140  5247.1  \n",
       "\n",
       "[25704 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds_on_ensemble_18_models = pd.read_csv('predictions_m3_nbeats_stack_moe_val_18.csv')\n",
    "preds_on_ensemble_18 = pd.read_csv('predictions_m3_nbeats_stack_moe_18.csv')\n",
    "preds_on_ensemble_18 = preds_on_ensemble_18.drop(columns=['prediction_agg'])\n",
    "val_preds_on_ensemble_18_models = val_preds_on_ensemble_18_models.drop(columns=['prediction_agg'])\n",
    "\n",
    "val_preds_on_ensemble_18_models['y'] = y_val['y'].values\n",
    "val_preds_on_ensemble_18_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b879682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for MoE training...\n",
      "Number of expert models: 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "MoE Training data shape: (20563, 18)\n",
      "MoE Validation data shape: (5141, 18)\n",
      "Using device: cuda\n",
      "Starting MoE training...\n",
      "Epoch 000: Train Loss = 0.241866, Val Loss = 0.208205\n",
      "Epoch 010: Train Loss = 0.214529, Val Loss = 0.184965\n",
      "Epoch 020: Train Loss = 0.204380, Val Loss = 0.179707\n",
      "Epoch 030: Train Loss = 0.198487, Val Loss = 0.182043\n",
      "Epoch 040: Train Loss = 0.196543, Val Loss = 0.180855\n",
      "Epoch 050: Train Loss = 0.197202, Val Loss = 0.178937\n",
      "Epoch 060: Train Loss = 0.186732, Val Loss = 0.174653\n",
      "Epoch 070: Train Loss = 0.183986, Val Loss = 0.176765\n",
      "Epoch 080: Train Loss = 0.181086, Val Loss = 0.174934\n",
      "Epoch 090: Train Loss = 0.175978, Val Loss = 0.172620\n",
      "Epoch 100: Train Loss = 0.169647, Val Loss = 0.173778\n",
      "Epoch 110: Train Loss = 0.169172, Val Loss = 0.172922\n",
      "Epoch 120: Train Loss = 0.168398, Val Loss = 0.173763\n",
      "Epoch 130: Train Loss = 0.167418, Val Loss = 0.171600\n",
      "Epoch 140: Train Loss = 0.165692, Val Loss = 0.171415\n",
      "Epoch 150: Train Loss = 0.165770, Val Loss = 0.170261\n",
      "Epoch 160: Train Loss = 0.164320, Val Loss = 0.174305\n",
      "Epoch 170: Train Loss = 0.165057, Val Loss = 0.171936\n",
      "Epoch 180: Train Loss = 0.163619, Val Loss = 0.170336\n",
      "Epoch 190: Train Loss = 0.163147, Val Loss = 0.168987\n",
      "Epoch 200: Train Loss = 0.162579, Val Loss = 0.168557\n",
      "Epoch 210: Train Loss = 0.162592, Val Loss = 0.169407\n",
      "Epoch 220: Train Loss = 0.162546, Val Loss = 0.168278\n",
      "Epoch 230: Train Loss = 0.161624, Val Loss = 0.168530\n",
      "Epoch 240: Train Loss = 0.162069, Val Loss = 0.168609\n",
      "Epoch 250: Train Loss = 0.163955, Val Loss = 0.169018\n",
      "Early stopping at epoch 252\n",
      "Best validation loss: 0.167359\n",
      "MoE Model sMAPE on test set: 0.1404\n",
      "MoE Model sMAPE on validation set: 0.1344\n",
      "\n",
      "Expert Importance (Average Gating Weights):\n",
      "NBeatsStackMoe16: 0.0779\n",
      "NBeatsStackMoe11: 0.0706\n",
      "NBeatsStackMoe: 0.0677\n",
      "NBeatsStackMoe9: 0.0677\n",
      "NBeatsStackMoe2: 0.0676\n",
      "NBeatsStackMoe14: 0.0652\n",
      "NBeatsStackMoe4: 0.0602\n",
      "NBeatsStackMoe6: 0.0585\n",
      "NBeatsStackMoe3: 0.0526\n",
      "NBeatsStackMoe7: 0.0519\n",
      "NBeatsStackMoe5: 0.0475\n",
      "NBeatsStackMoe8: 0.0472\n",
      "NBeatsStackMoe12: 0.0470\n",
      "NBeatsStackMoe1: 0.0465\n",
      "NBeatsStackMoe10: 0.0465\n",
      "NBeatsStackMoe15: 0.0451\n",
      "NBeatsStackMoe17: 0.0449\n",
      "NBeatsStackMoe13: 0.0356\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'predictions_m3_nbeats_stack_moe_with_moe_aggregation.csv'\n",
      "\n",
      "Comparison on validation set:\n",
      "Simple Average sMAPE: 0.2209\n",
      "Simple Median sMAPE: 0.1392\n",
      "MoE Model sMAPE: 0.1344\n",
      "Improvement(over average): 39.13%\n",
      "Improvement(over median): 3.40%\n",
      "\n",
      "Comparison on teest set:\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "MoE Model sMAPE: 0.1404\n",
      "Improvement(over average): -3.14%\n",
      "Improvement(over median): -3.47%\n",
      "\n",
      "Final Results Summary:\n",
      "- Number of expert models: 18\n",
      "- MoE model validation sMAPE: 0.1344\n",
      "- Test predictions generated: 25704\n",
      "- Most important expert: NBeatsStackMoe16 (weight: 0.0779)\n",
      "- Least important expert: NBeatsStackMoe13 (weight: 0.0356)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Prepare the validation data for training MoE\n",
    "print(\"Preparing data for MoE training...\")\n",
    "\n",
    "# Extract prediction columns (exclude unique_id, ds, and y)\n",
    "pred_columns = [col for col in val_preds_on_ensemble_18_models.columns \n",
    "                if col.startswith('NBeatsStackMoe') and col != 'y']\n",
    "\n",
    "print(f\"Number of expert models: {len(pred_columns)}\")\n",
    "\n",
    "# Extract features (individual model predictions) and target (aggregated prediction)\n",
    "X_val = val_preds_on_ensemble_18_models[pred_columns].values\n",
    "y_val = val_preds_on_ensemble_18_models['y'].values\n",
    "\n",
    "# For test set, we don't have the target, so we'll use it for final predictions\n",
    "X_test = preds_on_ensemble_18[pred_columns].values\n",
    "Y_test = y_test['y'].values\n",
    "\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "\n",
    "# Split validation data into train/val for MoE training\n",
    "X_train_moe, X_val_moe, y_train_moe, y_val_moe = sklearn_train_test_split(\n",
    "    X_val, y_val, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalize the features\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_moe_scaled = scaler_X.fit_transform(X_train_moe)\n",
    "X_val_moe_scaled = scaler_X.transform(X_val_moe)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "# Y_test_scaled = scaler_X.transform(Y_test)\n",
    "\n",
    "y_train_moe_scaled = scaler_y.fit_transform(y_train_moe.reshape(-1, 1)).flatten()\n",
    "y_val_moe_scaled = scaler_y.transform(y_val_moe.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"MoE Training data shape: {X_train_moe_scaled.shape}\")\n",
    "print(f\"MoE Validation data shape: {X_val_moe_scaled.shape}\")\n",
    "\n",
    "# Define the Mixture of Experts model\n",
    "class MixtureOfExpertsAggregator(nn.Module):\n",
    "    def __init__(self, num_experts, hidden_dim=64, dropout_rate=0.1):\n",
    "        super(MixtureOfExpertsAggregator, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        \n",
    "        # Simple MLP gating network that produces softmax weights\n",
    "        self.gating_network = nn.Sequential(\n",
    "            nn.Linear(num_experts, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, num_experts),\n",
    "            nn.Softmax(dim=1)  # Softmax to ensure weights sum to 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get gating weights from MLP\n",
    "        gating_weights = self.gating_network(x)\n",
    "        \n",
    "        # Weighted sum: multiply each input prediction by its corresponding weight\n",
    "        # x shape: (batch_size, num_experts)\n",
    "        # gating_weights shape: (batch_size, num_experts)\n",
    "        weighted_sum = torch.sum(gating_weights * x, dim=1, keepdim=True)\n",
    "        \n",
    "        return weighted_sum.squeeze(), gating_weights\n",
    "\n",
    "# Dataset class for PyTorch\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TimeSeriesDataset(X_train_moe_scaled, y_train_moe_scaled)\n",
    "val_dataset = TimeSeriesDataset(X_val_moe_scaled, y_val_moe_scaled)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "num_experts = len(pred_columns)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = MixtureOfExpertsAggregator(num_experts, hidden_dim=256, dropout_rate=0.10)\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, gating_weights = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Add regularization to encourage diverse gating\n",
    "        entropy_reg = -torch.mean(torch.sum(gating_weights * torch.log(gating_weights + 1e-8), dim=1))\n",
    "        total_loss_with_reg = loss - 0.01 * entropy_reg  # Encourage diversity\n",
    "        \n",
    "        total_loss_with_reg.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, _ = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting MoE training...\")\n",
    "num_epochs = 300\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience_limit = 30\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_moe_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch:03d}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}')\n",
    "    \n",
    "    if patience_counter >= patience_limit:\n",
    "        print(f'Early stopping at epoch {epoch}')\n",
    "        break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_moe_model.pth'))\n",
    "print(f'Best validation loss: {best_val_loss:.6f}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "def predict_moe_on_test(model, X_test_scaled, scaler_y, device, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Generate predictions and gating weights for the test set using the trained MoE model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained MixtureOfExpertsAggregator model.\n",
    "        X_test_scaled: Scaled test features (numpy array).\n",
    "        scaler_y: Fitted StandardScaler for inverse transforming predictions.\n",
    "        device: Torch device ('cuda' or 'cpu').\n",
    "        batch_size: Batch size for inference.\n",
    "\n",
    "    Returns:\n",
    "        test_predictions_original: Inverse-transformed predictions (numpy array).\n",
    "        test_gating_weights: Gating weights for each test sample (numpy array).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_gating_weights = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "        for i in range(0, len(test_tensor), batch_size):\n",
    "            batch = test_tensor[i:i + batch_size]\n",
    "            pred, gating = model(batch)\n",
    "            test_predictions.extend(pred.cpu().numpy())\n",
    "            test_gating_weights.extend(gating.cpu().numpy())\n",
    "\n",
    "    test_predictions = np.array(test_predictions)\n",
    "    test_gating_weights = np.array(test_gating_weights)\n",
    "    test_predictions_original = scaler_y.inverse_transform(test_predictions.reshape(-1, 1)).flatten()\n",
    "    return test_predictions_original, test_gating_weights\n",
    "\n",
    "\n",
    "# Use the function to get predictions and gating weights\n",
    "test_predictions_original, test_gating_weights = predict_moe_on_test(\n",
    "    model, X_test_scaled, scaler_y, device\n",
    ")\n",
    "\n",
    "val_predictions, val_gating_weights = predict_moe_on_test(\n",
    "    model, X_val_moe_scaled, scaler_y, device\n",
    ")\n",
    "\n",
    "# Add MoE predictions to the test dataframe\n",
    "preds_on_ensemble_18_moe = preds_on_ensemble_18.copy()\n",
    "preds_on_ensemble_18_moe['moe_prediction'] = test_predictions_original\n",
    "\n",
    "# noe on the test set\n",
    "moe_smape_test = calculate_smape(\n",
    "    y_test,\n",
    "    preds_on_ensemble_18_moe,\n",
    "    'moe_prediction'\n",
    ")\n",
    "print(f\"MoE Model sMAPE on test set: {moe_smape_test:.4f}\")\n",
    "\n",
    "val_predictions, val_gating_weights = predict_moe_on_test(\n",
    "    model, X_val_moe_scaled, scaler_y, device\n",
    ")\n",
    "\n",
    "moe_smape = calculate_smape(\n",
    "    pd.DataFrame({'y': y_val_moe, 'unique_id': ['test'] * len(y_val_moe)}),\n",
    "    val_predictions,\n",
    "    'moe_prediction'\n",
    ")\n",
    "\n",
    "print(f\"MoE Model sMAPE on validation set: {moe_smape:.4f}\")\n",
    "\n",
    "\n",
    "# Analyze gating weights to understand which experts are most important\n",
    "avg_gating_weights = np.mean(test_gating_weights, axis=0)\n",
    "expert_importance = dict(zip(pred_columns, avg_gating_weights))\n",
    "expert_importance_sorted = sorted(expert_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nExpert Importance (Average Gating Weights):\")\n",
    "for expert, weight in expert_importance_sorted:\n",
    "    print(f\"{expert}: {weight:.4f}\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('MoE Training Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(avg_gating_weights)), avg_gating_weights)\n",
    "plt.title('Average Expert Weights')\n",
    "plt.xlabel('Expert Index')\n",
    "plt.ylabel('Average Weight')\n",
    "plt.xticks(range(len(avg_gating_weights)), [f'E{i}' for i in range(len(avg_gating_weights))], rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the results\n",
    "preds_on_ensemble_18_moe.to_csv('predictions_m3_nbeats_stack_moe_with_moe_aggregation.csv', index=False)\n",
    "print(\"Results saved to 'predictions_m3_nbeats_stack_moe_with_moe_aggregation.csv'\")\n",
    "\n",
    "# Compare simple average vs MoE prediction on validation set\n",
    "simple_avg_val = np.mean(X_val, axis=1)\n",
    "simple_avg_smape = calculate_smape(\n",
    "    y_test,\n",
    "    simple_avg_val,\n",
    "    'simple_avg'\n",
    ")\n",
    "\n",
    "simple_median_val = np.median(X_val, axis=1)\n",
    "simple_median_smape = calculate_smape(\n",
    "    pd.DataFrame({'y': y_val, 'unique_id': ['test'] * len(y_val)}),\n",
    "    simple_median_val,\n",
    "    'simple_median'\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"\\nComparison on validation set:\")\n",
    "print(f\"Simple Average sMAPE: {simple_avg_smape:.4f}\")\n",
    "print(f\"Simple Median sMAPE: {simple_median_smape:.4f}\")\n",
    "print(f\"MoE Model sMAPE: {moe_smape:.4f}\")\n",
    "print(f\"Improvement(over average): {((simple_avg_smape - moe_smape) / simple_avg_smape * 100):.2f}%\")\n",
    "print(f\"Improvement(over median): {((simple_median_smape - moe_smape) / simple_median_smape * 100):.2f}%\")\n",
    "\n",
    "\n",
    "# Compare simple average vs MoE prediction on test set\n",
    "\n",
    "preds_on_ensemble_18['simple_avg'] = preds_on_ensemble_18[pred_columns].mean(axis=1)\n",
    "preds_on_ensemble_18['simple_median'] = preds_on_ensemble_18[pred_columns].median(axis=1)\n",
    "simple_avg_smape = calculate_smape(\n",
    "    y_test,\n",
    "    preds_on_ensemble_18,\n",
    "    'simple_avg'\n",
    ")\n",
    "\n",
    "simple_median_smape = calculate_smape(\n",
    "    y_test,\n",
    "    preds_on_ensemble_18,\n",
    "    'simple_median'\n",
    ")\n",
    "\n",
    "print(f\"\\nComparison on teest set:\")\n",
    "print(f\"Simple Average sMAPE: {simple_avg_smape:.4f}\")\n",
    "print(f\"Simple Median sMAPE: {simple_median_smape:.4f}\")\n",
    "print(f\"MoE Model sMAPE: {moe_smape_test:.4f}\")\n",
    "print(f\"Improvement(over average): {((simple_avg_smape - moe_smape_test) / simple_avg_smape * 100):.2f}%\")\n",
    "print(f\"Improvement(over median): {((simple_median_smape - moe_smape_test) / simple_median_smape * 100):.2f}%\")\n",
    "\n",
    "\n",
    "# Final predictions summary\n",
    "print(f\"\\nFinal Results Summary:\")\n",
    "print(f\"- Number of expert models: {num_experts}\")\n",
    "print(f\"- MoE model validation sMAPE: {moe_smape:.4f}\")\n",
    "print(f\"- Test predictions generated: {len(test_predictions_original)}\")\n",
    "print(f\"- Most important expert: {expert_importance_sorted[0][0]} (weight: {expert_importance_sorted[0][1]:.4f})\")\n",
    "print(f\"- Least important expert: {expert_importance_sorted[-1][0]} (weight: {expert_importance_sorted[-1][1]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc9dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To run the Top-K MoE with your existing data, simply call:\n",
      "\n",
      "results = run_topk_moe_training(\n",
      "    val_preds_on_ensemble_18_models,  # Your validation predictions DataFrame\n",
      "    preds_on_ensemble_18,             # Your test predictions DataFrame  \n",
      "    y_test,                           # Your test targets DataFrame\n",
      "    calculate_smape,                  # Your sMAPE calculation function\n",
      "    top_k_values=[8, 10, 12]         # Different k values to test\n",
      ")\n",
      "\n",
      "Key improvements in Top-K MoE:\n",
      "1. Selects top-k experts instead of using all experts\n",
      "2. Reduces noise from poor-performing experts\n",
      "3. Implements load balancing to encourage expert diversity\n",
      "4. Provides detailed analysis of expert selection patterns\n",
      "5. Tests multiple k values to find optimal sparsity\n",
      "\n",
      "The function will automatically:\n",
      "1. Test different k values (8, 10, 12 by default)\n",
      "      \n",
      "Starting Top-K MoE Training with your data...\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 1: {'use_series_info': True, 'aggregation_method': 'robust_weighted', 'top_k': 8}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=8)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of unique series: 1428\n",
      "Number of expert models: 18\n",
      "Using top-8 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: True\n",
      "Aggregation method: robust_weighted\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=8 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.229737, Val Loss = 0.194032\n",
      "Epoch 025: Train Loss = 0.166098, Val Loss = 0.174323\n",
      "Epoch 050: Train Loss = 0.169600, Val Loss = 0.178424\n",
      "Epoch 075: Train Loss = 0.160728, Val Loss = 0.161228\n",
      "Epoch 100: Train Loss = 0.147358, Val Loss = 0.167636\n",
      "Early stopping at epoch 115\n",
      "Model 1 - Best validation loss: 0.161228\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=8 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.244201, Val Loss = 0.190343\n",
      "Epoch 025: Train Loss = 0.161127, Val Loss = 0.161694\n",
      "Epoch 050: Train Loss = 0.161077, Val Loss = 0.184659\n",
      "Epoch 075: Train Loss = 0.157024, Val Loss = 0.163186\n",
      "Epoch 100: Train Loss = 0.151744, Val Loss = 0.163016\n",
      "Epoch 125: Train Loss = 0.147145, Val Loss = 0.159675\n",
      "Early stopping at epoch 146\n",
      "Model 2 - Best validation loss: 0.156637\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-8 MoE Ensemble sMAPE on test set: 0.1413\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-8 MoE Ensemble sMAPE: 0.1413\n",
      "Improvement over Average: -3.82%\n",
      "Improvement over Median: -4.15%\n",
      "\n",
      "--- Top-8 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe11: 0.737 (73.7%)\n",
      "NBeatsStackMoe6: 0.667 (66.7%)\n",
      "NBeatsStackMoe14: 0.636 (63.6%)\n",
      "NBeatsStackMoe2: 0.631 (63.1%)\n",
      "NBeatsStackMoe10: 0.568 (56.8%)\n",
      "NBeatsStackMoe4: 0.547 (54.7%)\n",
      "NBeatsStackMoe: 0.517 (51.7%)\n",
      "NBeatsStackMoe7: 0.507 (50.7%)\n",
      "NBeatsStackMoe9: 0.467 (46.7%)\n",
      "NBeatsStackMoe15: 0.459 (45.9%)\n",
      "NBeatsStackMoe17: 0.441 (44.1%)\n",
      "NBeatsStackMoe12: 0.438 (43.8%)\n",
      "NBeatsStackMoe5: 0.431 (43.1%)\n",
      "NBeatsStackMoe16: 0.374 (37.4%)\n",
      "NBeatsStackMoe3: 0.339 (33.9%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-8) ---\n",
      "NBeatsStackMoe11: 0.2751\n",
      "NBeatsStackMoe14: 0.2538\n",
      "NBeatsStackMoe: 0.1884\n",
      "NBeatsStackMoe7: 0.0570\n",
      "NBeatsStackMoe5: 0.0438\n",
      "NBeatsStackMoe6: 0.0430\n",
      "NBeatsStackMoe2: 0.0370\n",
      "NBeatsStackMoe10: 0.0302\n",
      "NBeatsStackMoe4: 0.0230\n",
      "NBeatsStackMoe15: 0.0108\n",
      "NBeatsStackMoe17: 0.0100\n",
      "NBeatsStackMoe3: 0.0099\n",
      "NBeatsStackMoe9: 0.0085\n",
      "NBeatsStackMoe16: 0.0050\n",
      "NBeatsStackMoe12: 0.0044\n",
      "\n",
      "Results saved to: topk_moe_predictions_k8_robust_weighted_with_series.csv\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 2: {'use_series_info': True, 'aggregation_method': 'weighted_median', 'top_k': 8}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=8)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of unique series: 1428\n",
      "Number of expert models: 18\n",
      "Using top-8 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: True\n",
      "Aggregation method: weighted_median\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=8 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.271049, Val Loss = 0.256072\n",
      "Epoch 025: Train Loss = 0.276617, Val Loss = 0.256163\n",
      "Epoch 050: Train Loss = 0.272498, Val Loss = 0.257001\n",
      "Early stopping at epoch 52\n",
      "Model 1 - Best validation loss: 0.249256\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=8 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.271292, Val Loss = 0.214360\n",
      "Epoch 025: Train Loss = 0.275802, Val Loss = 0.214181\n",
      "Epoch 050: Train Loss = 0.276632, Val Loss = 0.215216\n",
      "Early stopping at epoch 54\n",
      "Model 2 - Best validation loss: 0.205318\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-8 MoE Ensemble sMAPE on test set: 0.1441\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-8 MoE Ensemble sMAPE: 0.1441\n",
      "Improvement over Average: -5.88%\n",
      "Improvement over Median: -6.22%\n",
      "\n",
      "--- Top-8 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe13: 0.905 (90.5%)\n",
      "NBeatsStackMoe8: 0.834 (83.4%)\n",
      "NBeatsStackMoe16: 0.771 (77.1%)\n",
      "NBeatsStackMoe7: 0.765 (76.5%)\n",
      "NBeatsStackMoe2: 0.641 (64.1%)\n",
      "NBeatsStackMoe: 0.625 (62.5%)\n",
      "NBeatsStackMoe9: 0.586 (58.6%)\n",
      "NBeatsStackMoe6: 0.555 (55.5%)\n",
      "NBeatsStackMoe4: 0.402 (40.2%)\n",
      "NBeatsStackMoe12: 0.384 (38.4%)\n",
      "NBeatsStackMoe14: 0.375 (37.5%)\n",
      "NBeatsStackMoe15: 0.352 (35.2%)\n",
      "NBeatsStackMoe10: 0.311 (31.1%)\n",
      "NBeatsStackMoe11: 0.233 (23.3%)\n",
      "NBeatsStackMoe17: 0.100 (10.0%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-8) ---\n",
      "NBeatsStackMoe2: 0.4508\n",
      "NBeatsStackMoe: 0.3723\n",
      "NBeatsStackMoe4: 0.1769\n",
      "NBeatsStackMoe13: 0.0000\n",
      "NBeatsStackMoe16: 0.0000\n",
      "NBeatsStackMoe9: 0.0000\n",
      "NBeatsStackMoe8: 0.0000\n",
      "NBeatsStackMoe14: 0.0000\n",
      "NBeatsStackMoe6: 0.0000\n",
      "NBeatsStackMoe7: 0.0000\n",
      "NBeatsStackMoe15: 0.0000\n",
      "NBeatsStackMoe11: 0.0000\n",
      "NBeatsStackMoe12: 0.0000\n",
      "NBeatsStackMoe17: 0.0000\n",
      "NBeatsStackMoe1: 0.0000\n",
      "\n",
      "Results saved to: topk_moe_predictions_k8_weighted_median_with_series.csv\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 3: {'use_series_info': False, 'aggregation_method': 'robust_weighted', 'top_k': 8}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=8)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of expert models: 18\n",
      "Using top-8 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: False\n",
      "Aggregation method: robust_weighted\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=8 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.239643, Val Loss = 0.200622\n",
      "Epoch 025: Train Loss = 0.194040, Val Loss = 0.180494\n",
      "Epoch 050: Train Loss = 0.190439, Val Loss = 0.180786\n",
      "Epoch 075: Train Loss = 0.176051, Val Loss = 0.185222\n",
      "Epoch 100: Train Loss = 0.161816, Val Loss = 0.173745\n",
      "Epoch 125: Train Loss = 0.152311, Val Loss = 0.176909\n",
      "Early stopping at epoch 137\n",
      "Model 1 - Best validation loss: 0.172205\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=8 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.237603, Val Loss = 0.201816\n",
      "Epoch 025: Train Loss = 0.184452, Val Loss = 0.187730\n",
      "Epoch 050: Train Loss = 0.196190, Val Loss = 0.202448\n",
      "Epoch 075: Train Loss = 0.171207, Val Loss = 0.189942\n",
      "Epoch 100: Train Loss = 0.160709, Val Loss = 0.200173\n",
      "Epoch 125: Train Loss = 0.155719, Val Loss = 0.183158\n",
      "Early stopping at epoch 133\n",
      "Model 2 - Best validation loss: 0.178451\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-8 MoE Ensemble sMAPE on test set: 0.1401\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-8 MoE Ensemble sMAPE: 0.1401\n",
      "Improvement over Average: -2.90%\n",
      "Improvement over Median: -3.22%\n",
      "\n",
      "--- Top-8 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe: 0.939 (93.9%)\n",
      "NBeatsStackMoe4: 0.779 (77.9%)\n",
      "NBeatsStackMoe14: 0.745 (74.5%)\n",
      "NBeatsStackMoe9: 0.669 (66.9%)\n",
      "NBeatsStackMoe2: 0.628 (62.8%)\n",
      "NBeatsStackMoe11: 0.611 (61.1%)\n",
      "NBeatsStackMoe10: 0.481 (48.1%)\n",
      "NBeatsStackMoe15: 0.450 (45.0%)\n",
      "NBeatsStackMoe7: 0.413 (41.3%)\n",
      "NBeatsStackMoe6: 0.396 (39.6%)\n",
      "NBeatsStackMoe17: 0.379 (37.9%)\n",
      "NBeatsStackMoe16: 0.377 (37.7%)\n",
      "NBeatsStackMoe5: 0.354 (35.4%)\n",
      "NBeatsStackMoe12: 0.283 (28.3%)\n",
      "NBeatsStackMoe1: 0.252 (25.2%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-8) ---\n",
      "NBeatsStackMoe: 0.6902\n",
      "NBeatsStackMoe2: 0.2953\n",
      "NBeatsStackMoe11: 0.0046\n",
      "NBeatsStackMoe15: 0.0031\n",
      "NBeatsStackMoe7: 0.0021\n",
      "NBeatsStackMoe3: 0.0009\n",
      "NBeatsStackMoe5: 0.0007\n",
      "NBeatsStackMoe12: 0.0007\n",
      "NBeatsStackMoe9: 0.0007\n",
      "NBeatsStackMoe14: 0.0004\n",
      "NBeatsStackMoe16: 0.0004\n",
      "NBeatsStackMoe17: 0.0002\n",
      "NBeatsStackMoe4: 0.0002\n",
      "NBeatsStackMoe13: 0.0002\n",
      "NBeatsStackMoe10: 0.0001\n",
      "\n",
      "Results saved to: topk_moe_predictions_k8_robust_weighted_no_series.csv\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 4: {'use_series_info': True, 'aggregation_method': 'robust_weighted', 'top_k': 10}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=10)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of unique series: 1428\n",
      "Number of expert models: 18\n",
      "Using top-10 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: True\n",
      "Aggregation method: robust_weighted\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=10 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.233968, Val Loss = 0.190010\n",
      "Epoch 025: Train Loss = 0.165795, Val Loss = 0.172089\n",
      "Epoch 050: Train Loss = 0.166745, Val Loss = 0.175170\n",
      "Epoch 075: Train Loss = 0.164161, Val Loss = 0.172981\n",
      "Epoch 100: Train Loss = 0.133205, Val Loss = 0.169186\n",
      "Epoch 125: Train Loss = 0.128664, Val Loss = 0.176292\n",
      "Early stopping at epoch 144\n",
      "Model 1 - Best validation loss: 0.165710\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=10 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.231882, Val Loss = 0.189982\n",
      "Epoch 025: Train Loss = 0.173757, Val Loss = 0.173953\n",
      "Epoch 050: Train Loss = 0.179234, Val Loss = 0.175358\n",
      "Early stopping at epoch 53\n",
      "Model 2 - Best validation loss: 0.161250\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-10 MoE Ensemble sMAPE on test set: 0.1408\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-10 MoE Ensemble sMAPE: 0.1408\n",
      "Improvement over Average: -3.43%\n",
      "Improvement over Median: -3.76%\n",
      "\n",
      "--- Top-10 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe: 0.990 (99.0%)\n",
      "NBeatsStackMoe2: 0.772 (77.2%)\n",
      "NBeatsStackMoe11: 0.756 (75.6%)\n",
      "NBeatsStackMoe10: 0.710 (71.0%)\n",
      "NBeatsStackMoe1: 0.679 (67.9%)\n",
      "NBeatsStackMoe6: 0.617 (61.7%)\n",
      "NBeatsStackMoe4: 0.600 (60.0%)\n",
      "NBeatsStackMoe3: 0.553 (55.3%)\n",
      "NBeatsStackMoe14: 0.544 (54.4%)\n",
      "NBeatsStackMoe16: 0.537 (53.7%)\n",
      "NBeatsStackMoe13: 0.494 (49.4%)\n",
      "NBeatsStackMoe17: 0.463 (46.3%)\n",
      "NBeatsStackMoe9: 0.450 (45.0%)\n",
      "NBeatsStackMoe7: 0.415 (41.5%)\n",
      "NBeatsStackMoe12: 0.405 (40.5%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-10) ---\n",
      "NBeatsStackMoe: 0.7839\n",
      "NBeatsStackMoe10: 0.1410\n",
      "NBeatsStackMoe2: 0.0426\n",
      "NBeatsStackMoe17: 0.0118\n",
      "NBeatsStackMoe11: 0.0085\n",
      "NBeatsStackMoe5: 0.0071\n",
      "NBeatsStackMoe3: 0.0020\n",
      "NBeatsStackMoe4: 0.0011\n",
      "NBeatsStackMoe14: 0.0008\n",
      "NBeatsStackMoe7: 0.0004\n",
      "NBeatsStackMoe12: 0.0003\n",
      "NBeatsStackMoe9: 0.0002\n",
      "NBeatsStackMoe6: 0.0001\n",
      "NBeatsStackMoe8: 0.0001\n",
      "NBeatsStackMoe1: 0.0001\n",
      "\n",
      "Results saved to: topk_moe_predictions_k10_robust_weighted_with_series.csv\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 5: {'use_series_info': True, 'aggregation_method': 'weighted_median', 'top_k': 10}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=10)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of unique series: 1428\n",
      "Number of expert models: 18\n",
      "Using top-10 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: True\n",
      "Aggregation method: weighted_median\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=10 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.280837, Val Loss = 0.256503\n",
      "Epoch 025: Train Loss = 0.285280, Val Loss = 0.255174\n",
      "Epoch 050: Train Loss = 0.285503, Val Loss = 0.255192\n",
      "Epoch 075: Train Loss = 0.284103, Val Loss = 0.259158\n",
      "Early stopping at epoch 96\n",
      "Model 1 - Best validation loss: 0.240755\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=10 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.345664, Val Loss = 0.241951\n",
      "Epoch 025: Train Loss = 0.352511, Val Loss = 0.242964\n",
      "Early stopping at epoch 46\n",
      "Model 2 - Best validation loss: 0.239726\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-10 MoE Ensemble sMAPE on test set: 0.1415\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-10 MoE Ensemble sMAPE: 0.1415\n",
      "Improvement over Average: -3.91%\n",
      "Improvement over Median: -4.24%\n",
      "\n",
      "--- Top-10 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe: 0.984 (98.4%)\n",
      "NBeatsStackMoe2: 0.958 (95.8%)\n",
      "NBeatsStackMoe10: 0.621 (62.1%)\n",
      "NBeatsStackMoe12: 0.619 (61.9%)\n",
      "NBeatsStackMoe11: 0.577 (57.7%)\n",
      "NBeatsStackMoe14: 0.569 (56.9%)\n",
      "NBeatsStackMoe9: 0.566 (56.6%)\n",
      "NBeatsStackMoe3: 0.532 (53.2%)\n",
      "NBeatsStackMoe16: 0.520 (52.0%)\n",
      "NBeatsStackMoe8: 0.517 (51.7%)\n",
      "NBeatsStackMoe4: 0.490 (49.0%)\n",
      "NBeatsStackMoe13: 0.477 (47.7%)\n",
      "NBeatsStackMoe6: 0.476 (47.6%)\n",
      "NBeatsStackMoe15: 0.467 (46.7%)\n",
      "NBeatsStackMoe1: 0.465 (46.5%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-10) ---\n",
      "NBeatsStackMoe11: 0.5299\n",
      "NBeatsStackMoe16: 0.4701\n",
      "NBeatsStackMoe9: 0.0000\n",
      "NBeatsStackMoe14: 0.0000\n",
      "NBeatsStackMoe10: 0.0000\n",
      "NBeatsStackMoe: 0.0000\n",
      "NBeatsStackMoe2: 0.0000\n",
      "NBeatsStackMoe6: 0.0000\n",
      "NBeatsStackMoe3: 0.0000\n",
      "NBeatsStackMoe13: 0.0000\n",
      "NBeatsStackMoe5: 0.0000\n",
      "NBeatsStackMoe15: 0.0000\n",
      "NBeatsStackMoe12: 0.0000\n",
      "NBeatsStackMoe8: 0.0000\n",
      "NBeatsStackMoe4: 0.0000\n",
      "\n",
      "Results saved to: topk_moe_predictions_k10_weighted_median_with_series.csv\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 6: {'use_series_info': False, 'aggregation_method': 'robust_weighted', 'top_k': 10}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=10)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of expert models: 18\n",
      "Using top-10 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: False\n",
      "Aggregation method: robust_weighted\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=10 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.254109, Val Loss = 0.195942\n",
      "Epoch 025: Train Loss = 0.185612, Val Loss = 0.182172\n",
      "Epoch 050: Train Loss = 0.197332, Val Loss = 0.178181\n",
      "Epoch 075: Train Loss = 0.171929, Val Loss = 0.175270\n",
      "Epoch 100: Train Loss = 0.159623, Val Loss = 0.175182\n",
      "Epoch 125: Train Loss = 0.153934, Val Loss = 0.184158\n",
      "Early stopping at epoch 138\n",
      "Model 1 - Best validation loss: 0.170734\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=10 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.259430, Val Loss = 0.205389\n",
      "Epoch 025: Train Loss = 0.191616, Val Loss = 0.225239\n",
      "Epoch 050: Train Loss = 0.187026, Val Loss = 0.226415\n",
      "Epoch 075: Train Loss = 0.177999, Val Loss = 0.183282\n",
      "Epoch 100: Train Loss = 0.167997, Val Loss = 0.215780\n",
      "Epoch 125: Train Loss = 0.157714, Val Loss = 0.196879\n",
      "Early stopping at epoch 131\n",
      "Model 2 - Best validation loss: 0.173463\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-10 MoE Ensemble sMAPE on test set: 0.1395\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-10 MoE Ensemble sMAPE: 0.1395\n",
      "Improvement over Average: -2.48%\n",
      "Improvement over Median: -2.81%\n",
      "\n",
      "--- Top-10 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe14: 0.929 (92.9%)\n",
      "NBeatsStackMoe16: 0.917 (91.7%)\n",
      "NBeatsStackMoe2: 0.908 (90.8%)\n",
      "NBeatsStackMoe9: 0.883 (88.3%)\n",
      "NBeatsStackMoe11: 0.728 (72.8%)\n",
      "NBeatsStackMoe10: 0.702 (70.2%)\n",
      "NBeatsStackMoe6: 0.671 (67.1%)\n",
      "NBeatsStackMoe5: 0.668 (66.8%)\n",
      "NBeatsStackMoe17: 0.629 (62.9%)\n",
      "NBeatsStackMoe12: 0.601 (60.1%)\n",
      "NBeatsStackMoe7: 0.465 (46.5%)\n",
      "NBeatsStackMoe3: 0.400 (40.0%)\n",
      "NBeatsStackMoe: 0.374 (37.4%)\n",
      "NBeatsStackMoe1: 0.338 (33.8%)\n",
      "NBeatsStackMoe15: 0.289 (28.9%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-10) ---\n",
      "NBeatsStackMoe14: 0.7499\n",
      "NBeatsStackMoe2: 0.2408\n",
      "NBeatsStackMoe11: 0.0056\n",
      "NBeatsStackMoe13: 0.0006\n",
      "NBeatsStackMoe15: 0.0006\n",
      "NBeatsStackMoe: 0.0006\n",
      "NBeatsStackMoe3: 0.0005\n",
      "NBeatsStackMoe7: 0.0003\n",
      "NBeatsStackMoe12: 0.0003\n",
      "NBeatsStackMoe16: 0.0002\n",
      "NBeatsStackMoe5: 0.0002\n",
      "NBeatsStackMoe9: 0.0001\n",
      "NBeatsStackMoe17: 0.0001\n",
      "NBeatsStackMoe10: 0.0001\n",
      "NBeatsStackMoe1: 0.0001\n",
      "\n",
      "Results saved to: topk_moe_predictions_k10_robust_weighted_no_series.csv\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 7: {'use_series_info': True, 'aggregation_method': 'robust_weighted', 'top_k': 12}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=12)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of unique series: 1428\n",
      "Number of expert models: 18\n",
      "Using top-12 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: True\n",
      "Aggregation method: robust_weighted\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=12 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.234274, Val Loss = 0.200145\n",
      "Epoch 025: Train Loss = 0.171900, Val Loss = 0.174242\n",
      "Epoch 050: Train Loss = 0.171477, Val Loss = 0.173414\n",
      "Epoch 075: Train Loss = 0.148438, Val Loss = 0.169846\n",
      "Epoch 100: Train Loss = 0.141897, Val Loss = 0.167103\n",
      "Epoch 125: Train Loss = 0.131994, Val Loss = 0.166209\n",
      "Early stopping at epoch 128\n",
      "Model 1 - Best validation loss: 0.165732\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=12 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.240187, Val Loss = 0.208821\n",
      "Epoch 025: Train Loss = 0.171345, Val Loss = 0.156691\n",
      "Epoch 050: Train Loss = 0.172971, Val Loss = 0.157563\n",
      "Epoch 075: Train Loss = 0.163894, Val Loss = 0.158457\n",
      "Epoch 100: Train Loss = 0.158738, Val Loss = 0.153477\n",
      "Epoch 125: Train Loss = 0.145575, Val Loss = 0.164450\n",
      "Epoch 150: Train Loss = 0.157771, Val Loss = 0.148338\n",
      "Early stopping at epoch 151\n",
      "Model 2 - Best validation loss: 0.147360\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-12 MoE Ensemble sMAPE on test set: 0.1405\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-12 MoE Ensemble sMAPE: 0.1405\n",
      "Improvement over Average: -3.22%\n",
      "Improvement over Median: -3.55%\n",
      "\n",
      "--- Top-12 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe5: 1.000 (100.0%)\n",
      "NBeatsStackMoe9: 0.855 (85.5%)\n",
      "NBeatsStackMoe10: 0.830 (83.0%)\n",
      "NBeatsStackMoe16: 0.820 (82.0%)\n",
      "NBeatsStackMoe2: 0.820 (82.0%)\n",
      "NBeatsStackMoe8: 0.816 (81.6%)\n",
      "NBeatsStackMoe6: 0.801 (80.1%)\n",
      "NBeatsStackMoe4: 0.718 (71.8%)\n",
      "NBeatsStackMoe: 0.712 (71.2%)\n",
      "NBeatsStackMoe17: 0.655 (65.5%)\n",
      "NBeatsStackMoe14: 0.646 (64.6%)\n",
      "NBeatsStackMoe11: 0.633 (63.3%)\n",
      "NBeatsStackMoe3: 0.610 (61.0%)\n",
      "NBeatsStackMoe12: 0.597 (59.7%)\n",
      "NBeatsStackMoe1: 0.535 (53.5%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-12) ---\n",
      "NBeatsStackMoe5: 0.8620\n",
      "NBeatsStackMoe: 0.1318\n",
      "NBeatsStackMoe15: 0.0025\n",
      "NBeatsStackMoe16: 0.0015\n",
      "NBeatsStackMoe8: 0.0010\n",
      "NBeatsStackMoe10: 0.0003\n",
      "NBeatsStackMoe7: 0.0002\n",
      "NBeatsStackMoe2: 0.0002\n",
      "NBeatsStackMoe12: 0.0001\n",
      "NBeatsStackMoe4: 0.0001\n",
      "NBeatsStackMoe11: 0.0001\n",
      "NBeatsStackMoe6: 0.0001\n",
      "NBeatsStackMoe17: 0.0001\n",
      "NBeatsStackMoe3: 0.0001\n",
      "NBeatsStackMoe9: 0.0001\n",
      "\n",
      "Results saved to: topk_moe_predictions_k12_robust_weighted_with_series.csv\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 8: {'use_series_info': True, 'aggregation_method': 'weighted_median', 'top_k': 12}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=12)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of unique series: 1428\n",
      "Number of expert models: 18\n",
      "Using top-12 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: True\n",
      "Aggregation method: weighted_median\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=12 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.295731, Val Loss = 0.300031\n",
      "Epoch 025: Train Loss = 0.300672, Val Loss = 0.283139\n",
      "Epoch 050: Train Loss = 0.302880, Val Loss = 0.280254\n",
      "Epoch 075: Train Loss = 0.295498, Val Loss = 0.275830\n",
      "Epoch 100: Train Loss = 0.295039, Val Loss = 0.282940\n",
      "Early stopping at epoch 109\n",
      "Model 1 - Best validation loss: 0.272428\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=12 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.289773, Val Loss = 0.243588\n",
      "Epoch 025: Train Loss = 0.299198, Val Loss = 0.241850\n",
      "Early stopping at epoch 42\n",
      "Model 2 - Best validation loss: 0.241470\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-12 MoE Ensemble sMAPE on test set: 0.1539\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-12 MoE Ensemble sMAPE: 0.1539\n",
      "Improvement over Average: -13.06%\n",
      "Improvement over Median: -13.42%\n",
      "\n",
      "--- Top-12 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe3: 0.991 (99.1%)\n",
      "NBeatsStackMoe5: 0.952 (95.2%)\n",
      "NBeatsStackMoe17: 0.932 (93.2%)\n",
      "NBeatsStackMoe: 0.904 (90.4%)\n",
      "NBeatsStackMoe14: 0.876 (87.6%)\n",
      "NBeatsStackMoe7: 0.874 (87.4%)\n",
      "NBeatsStackMoe15: 0.795 (79.5%)\n",
      "NBeatsStackMoe2: 0.732 (73.2%)\n",
      "NBeatsStackMoe11: 0.674 (67.4%)\n",
      "NBeatsStackMoe6: 0.650 (65.0%)\n",
      "NBeatsStackMoe10: 0.562 (56.2%)\n",
      "NBeatsStackMoe4: 0.547 (54.7%)\n",
      "NBeatsStackMoe1: 0.536 (53.6%)\n",
      "NBeatsStackMoe8: 0.471 (47.1%)\n",
      "NBeatsStackMoe13: 0.449 (44.9%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-12) ---\n",
      "NBeatsStackMoe4: 0.3472\n",
      "NBeatsStackMoe8: 0.3048\n",
      "NBeatsStackMoe13: 0.3005\n",
      "NBeatsStackMoe16: 0.0475\n",
      "NBeatsStackMoe6: 0.0000\n",
      "NBeatsStackMoe17: 0.0000\n",
      "NBeatsStackMoe7: 0.0000\n",
      "NBeatsStackMoe15: 0.0000\n",
      "NBeatsStackMoe3: 0.0000\n",
      "NBeatsStackMoe1: 0.0000\n",
      "NBeatsStackMoe2: 0.0000\n",
      "NBeatsStackMoe14: 0.0000\n",
      "NBeatsStackMoe5: 0.0000\n",
      "NBeatsStackMoe10: 0.0000\n",
      "NBeatsStackMoe11: 0.0000\n",
      "\n",
      "Results saved to: topk_moe_predictions_k12_weighted_median_with_series.csv\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION 9: {'use_series_info': False, 'aggregation_method': 'robust_weighted', 'top_k': 12}\n",
      "============================================================\n",
      "==================================================\n",
      "TOP-K MoE TRAINING PIPELINE (k=12)\n",
      "==================================================\n",
      "Preparing enhanced data...\n",
      "Number of expert models: 18\n",
      "Using top-12 experts out of 18\n",
      "Validation data shape: (25704, 18)\n",
      "Test data shape: (25704, 18)\n",
      "Using series info: False\n",
      "Aggregation method: robust_weighted\n",
      "\n",
      "--- Training Model 1/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=12 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.262352, Val Loss = 0.221261\n",
      "Epoch 025: Train Loss = 0.194466, Val Loss = 0.183429\n",
      "Epoch 050: Train Loss = 0.181157, Val Loss = 0.181580\n",
      "Epoch 075: Train Loss = 0.183867, Val Loss = 0.183710\n",
      "Epoch 100: Train Loss = 0.164308, Val Loss = 0.180292\n",
      "Epoch 125: Train Loss = 0.157964, Val Loss = 0.186155\n",
      "Epoch 150: Train Loss = 0.167824, Val Loss = 0.181215\n",
      "Epoch 175: Train Loss = 0.161194, Val Loss = 0.180410\n",
      "Early stopping at epoch 180\n",
      "Model 1 - Best validation loss: 0.172781\n",
      "\n",
      "--- Training Model 2/2 ---\n",
      "Using device: cuda\n",
      "Initializing Top-K MoE with k=12 out of 18 experts\n",
      "Starting training...\n",
      "Epoch 000: Train Loss = 0.249381, Val Loss = 0.208024\n",
      "Epoch 025: Train Loss = 0.194804, Val Loss = 0.183572\n",
      "Epoch 050: Train Loss = 0.185953, Val Loss = 0.211742\n",
      "Epoch 075: Train Loss = 0.175629, Val Loss = 0.201154\n",
      "Epoch 100: Train Loss = 0.156551, Val Loss = 0.190203\n",
      "Epoch 125: Train Loss = 0.147862, Val Loss = 0.198482\n",
      "Early stopping at epoch 137\n",
      "Model 2 - Best validation loss: 0.179999\n",
      "\n",
      "--- Creating Ensemble Predictions ---\n",
      "Top-12 MoE Ensemble sMAPE on test set: 0.1407\n",
      "\n",
      "--- Comparison with Baselines ---\n",
      "Simple Average sMAPE: 0.1361\n",
      "Simple Median sMAPE: 0.1357\n",
      "Top-12 MoE Ensemble sMAPE: 0.1407\n",
      "Improvement over Average: -3.34%\n",
      "Improvement over Median: -3.67%\n",
      "\n",
      "--- Top-12 Expert Selection Analysis ---\n",
      "Most frequently selected experts:\n",
      "NBeatsStackMoe14: 1.000 (100.0%)\n",
      "NBeatsStackMoe11: 0.965 (96.5%)\n",
      "NBeatsStackMoe9: 0.960 (96.0%)\n",
      "NBeatsStackMoe2: 0.951 (95.1%)\n",
      "NBeatsStackMoe16: 0.944 (94.4%)\n",
      "NBeatsStackMoe5: 0.906 (90.6%)\n",
      "NBeatsStackMoe7: 0.890 (89.0%)\n",
      "NBeatsStackMoe17: 0.792 (79.2%)\n",
      "NBeatsStackMoe12: 0.790 (79.0%)\n",
      "NBeatsStackMoe6: 0.703 (70.3%)\n",
      "NBeatsStackMoe: 0.571 (57.1%)\n",
      "NBeatsStackMoe10: 0.524 (52.4%)\n",
      "NBeatsStackMoe3: 0.520 (52.0%)\n",
      "NBeatsStackMoe8: 0.403 (40.3%)\n",
      "NBeatsStackMoe15: 0.381 (38.1%)\n",
      "\n",
      "--- Expert Importance (Average Gating Weights for Top-12) ---\n",
      "NBeatsStackMoe14: 0.9980\n",
      "NBeatsStackMoe7: 0.0008\n",
      "NBeatsStackMoe10: 0.0003\n",
      "NBeatsStackMoe16: 0.0003\n",
      "NBeatsStackMoe3: 0.0002\n",
      "NBeatsStackMoe11: 0.0001\n",
      "NBeatsStackMoe12: 0.0001\n",
      "NBeatsStackMoe4: 0.0001\n",
      "NBeatsStackMoe: 0.0001\n",
      "NBeatsStackMoe2: 0.0001\n",
      "NBeatsStackMoe1: 0.0000\n",
      "NBeatsStackMoe5: 0.0000\n",
      "NBeatsStackMoe13: 0.0000\n",
      "NBeatsStackMoe17: 0.0000\n",
      "NBeatsStackMoe9: 0.0000\n",
      "\n",
      "Results saved to: topk_moe_predictions_k12_robust_weighted_no_series.csv\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "Best configuration: {'use_series_info': False, 'aggregation_method': 'robust_weighted', 'top_k': 10}\n",
      "Best sMAPE: 0.1395\n",
      "\n",
      "--- All Configuration Results ---\n",
      "config_1: sMAPE = 0.1413, top_k = 8\n",
      "config_2: sMAPE = 0.1441, top_k = 8\n",
      "config_3: sMAPE = 0.1401, top_k = 8\n",
      "config_4: sMAPE = 0.1408, top_k = 10\n",
      "config_5: sMAPE = 0.1415, top_k = 10\n",
      "config_6: sMAPE = 0.1395, top_k = 10\n",
      "config_7: sMAPE = 0.1405, top_k = 12\n",
      "config_8: sMAPE = 0.1539, top_k = 12\n",
      "config_9: sMAPE = 0.1407, top_k = 12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== ENHANCED MODEL CLASSES ==========\n",
    "\n",
    "class EnhancedMixtureOfExpertsAggregator(nn.Module):\n",
    "    def __init__(self, num_experts, num_series=None, series_embed_dim=16, \n",
    "                 hidden_dim=128, dropout_rate=0.1, use_series_info=True,\n",
    "                 aggregation_method='robust_weighted'):\n",
    "        super(EnhancedMixtureOfExpertsAggregator, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.use_series_info = use_series_info\n",
    "        self.aggregation_method = aggregation_method\n",
    "        \n",
    "        # Series embedding if using series information\n",
    "        if use_series_info and num_series:\n",
    "            self.series_embedding = nn.Embedding(num_series, series_embed_dim)\n",
    "            gating_input_dim = num_experts + series_embed_dim\n",
    "        else:\n",
    "            gating_input_dim = num_experts\n",
    "            \n",
    "        # Enhanced gating network with batch normalization\n",
    "        self.gating_network = nn.Sequential(\n",
    "            nn.Linear(gating_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, num_experts)\n",
    "        )\n",
    "        \n",
    "        # Additional networks for different aggregation methods\n",
    "        if aggregation_method == 'weighted_median':\n",
    "            self.final_activation = nn.Softmax(dim=1)\n",
    "        elif aggregation_method == 'robust_weighted':\n",
    "            self.final_activation = nn.Softmax(dim=1)\n",
    "            self.outlier_detector = nn.Sequential(\n",
    "                nn.Linear(num_experts, hidden_dim // 4),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim // 4, num_experts),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        else:\n",
    "            self.final_activation = nn.Softmax(dim=1)\n",
    "            \n",
    "    def weighted_median(self, values, weights):\n",
    "        \"\"\"Compute weighted median\"\"\"\n",
    "        sorted_indices = torch.argsort(values, dim=1)\n",
    "        sorted_values = torch.gather(values, 1, sorted_indices)\n",
    "        sorted_weights = torch.gather(weights, 1, sorted_indices)\n",
    "        \n",
    "        cumsum_weights = torch.cumsum(sorted_weights, dim=1)\n",
    "        total_weights = cumsum_weights[:, -1:]\n",
    "        median_pos = total_weights * 0.5\n",
    "        \n",
    "        median_mask = cumsum_weights >= median_pos\n",
    "        median_indices = torch.argmax(median_mask.float(), dim=1)\n",
    "        \n",
    "        median_values = torch.gather(sorted_values, 1, median_indices.unsqueeze(1))\n",
    "        return median_values.squeeze(1)\n",
    "    \n",
    "    def forward(self, x, series_ids=None):\n",
    "        # Prepare input for gating network\n",
    "        if self.use_series_info and series_ids is not None:\n",
    "            series_embed = self.series_embedding(series_ids)\n",
    "            gating_input = torch.cat([x, series_embed], dim=1)\n",
    "        else:\n",
    "            gating_input = x\n",
    "            \n",
    "        # Get gating logits\n",
    "        gating_logits = self.gating_network(gating_input)\n",
    "        gating_weights = self.final_activation(gating_logits)\n",
    "        \n",
    "        if self.aggregation_method == 'weighted_sum':\n",
    "            output = torch.sum(gating_weights * x, dim=1)\n",
    "        elif self.aggregation_method == 'weighted_median':\n",
    "            output = self.weighted_median(x, gating_weights)\n",
    "        elif self.aggregation_method == 'robust_weighted':\n",
    "            confidence_scores = self.outlier_detector(x)\n",
    "            robust_weights = gating_weights * confidence_scores\n",
    "            robust_weights = robust_weights / (torch.sum(robust_weights, dim=1, keepdim=True) + 1e-8)\n",
    "            output = torch.sum(robust_weights * x, dim=1)\n",
    "        else:\n",
    "            output = torch.sum(gating_weights * x, dim=1)\n",
    "            \n",
    "        return output, gating_weights\n",
    "\n",
    "class EnhancedTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y, series_ids=None):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        self.series_ids = torch.LongTensor(series_ids) if series_ids is not None else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.series_ids is not None:\n",
    "            return self.X[idx], self.y[idx], self.series_ids[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ========== HELPER FUNCTIONS ==========\n",
    "\n",
    "def prepare_enhanced_data(val_preds_df, test_preds_df, use_series_info=True):\n",
    "    \"\"\"Prepare data with optional series information encoding\"\"\"\n",
    "    pred_columns = [col for col in val_preds_df.columns \n",
    "                    if col.startswith('NBeatsStackMoe') and col != 'y']\n",
    "    \n",
    "    X_val = val_preds_df[pred_columns].values\n",
    "    y_val = val_preds_df['y'].values\n",
    "    X_test = test_preds_df[pred_columns].values\n",
    "    \n",
    "    series_ids_val = None\n",
    "    series_ids_test = None\n",
    "    num_series = None\n",
    "    label_encoder = None\n",
    "    \n",
    "    if use_series_info and 'unique_id' in val_preds_df.columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        all_series = pd.concat([val_preds_df['unique_id'], test_preds_df['unique_id']]).unique()\n",
    "        label_encoder.fit(all_series)\n",
    "        \n",
    "        series_ids_val = label_encoder.transform(val_preds_df['unique_id'])\n",
    "        series_ids_test = label_encoder.transform(test_preds_df['unique_id'])\n",
    "        num_series = len(all_series)\n",
    "        \n",
    "        print(f\"Number of unique series: {num_series}\")\n",
    "    \n",
    "    return (X_val, y_val, X_test, series_ids_val, series_ids_test, \n",
    "            num_series, pred_columns, label_encoder)\n",
    "\n",
    "def train_enhanced_epoch(model, train_loader, criterion, optimizer, device, use_series_info=True):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        if use_series_info and len(batch) == 3:\n",
    "            data, target, series_ids = batch\n",
    "            data, target, series_ids = data.to(device), target.to(device), series_ids.to(device)\n",
    "        else:\n",
    "            data, target = batch[:2]\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            series_ids = None\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_series_info and series_ids is not None:\n",
    "            output, gating_weights = model(data, series_ids)\n",
    "        else:\n",
    "            output, gating_weights = model(data)\n",
    "            \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Enhanced regularization\n",
    "        entropy_reg = -torch.mean(torch.sum(gating_weights * torch.log(gating_weights + 1e-8), dim=1))\n",
    "        l2_reg = torch.mean(torch.sum(gating_weights ** 2, dim=1))\n",
    "        sparsity_reg = torch.mean(torch.sum(torch.abs(gating_weights), dim=1))\n",
    "        \n",
    "        total_loss_with_reg = (loss + \n",
    "                              0.01 * entropy_reg - \n",
    "                              0.005 * l2_reg + \n",
    "                              0.001 * sparsity_reg)\n",
    "        \n",
    "        total_loss_with_reg.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate_enhanced_epoch(model, val_loader, criterion, device, use_series_info=True):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if use_series_info and len(batch) == 3:\n",
    "                data, target, series_ids = batch\n",
    "                data, target, series_ids = data.to(device), target.to(device), series_ids.to(device)\n",
    "            else:\n",
    "                data, target = batch[:2]\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                series_ids = None\n",
    "            \n",
    "            if use_series_info and series_ids is not None:\n",
    "                output, _ = model(data, series_ids)\n",
    "            else:\n",
    "                output, _ = model(data)\n",
    "                \n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def predict_enhanced_moe(model, X_scaled, series_ids, scaler_y, device, \n",
    "                        use_series_info=True, batch_size=1000):\n",
    "    \"\"\"Enhanced prediction with series information\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    gating_weights = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.FloatTensor(X_scaled).to(device)\n",
    "        \n",
    "        if use_series_info and series_ids is not None:\n",
    "            series_tensor = torch.LongTensor(series_ids).to(device)\n",
    "        \n",
    "        for i in range(0, len(X_tensor), batch_size):\n",
    "            batch_X = X_tensor[i:i + batch_size]\n",
    "            \n",
    "            if use_series_info and series_ids is not None:\n",
    "                batch_series = series_tensor[i:i + batch_size]\n",
    "                pred, gating = model(batch_X, batch_series)\n",
    "            else:\n",
    "                pred, gating = model(batch_X)\n",
    "                \n",
    "            predictions.extend(pred.cpu().numpy())\n",
    "            gating_weights.extend(gating.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    gating_weights = np.array(gating_weights)\n",
    "    predictions_original = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return predictions_original, gating_weights\n",
    "\n",
    "# ========== MAIN TRAINING FUNCTION ==========\n",
    "\n",
    "def train_enhanced_moe_complete(val_preds_df, test_preds_df, y_test_df, calculate_smape_func,\n",
    "                               use_series_info=True, aggregation_method='robust_weighted',\n",
    "                               num_models=3):  # Train ensemble of models\n",
    "    \"\"\"\n",
    "    Complete enhanced MoE training pipeline\n",
    "    \"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"ENHANCED MoE TRAINING PIPELINE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"Preparing enhanced data...\")\n",
    "    (X_val, y_val, X_test, series_ids_val, series_ids_test, \n",
    "     num_series, pred_columns, label_encoder) = prepare_enhanced_data(\n",
    "        val_preds_df, test_preds_df, use_series_info)\n",
    "    \n",
    "    print(f\"Number of expert models: {len(pred_columns)}\")\n",
    "    print(f\"Validation data shape: {X_val.shape}\")\n",
    "    print(f\"Test data shape: {X_test.shape}\")\n",
    "    print(f\"Using series info: {use_series_info}\")\n",
    "    print(f\"Aggregation method: {aggregation_method}\")\n",
    "    \n",
    "    # Train ensemble of models\n",
    "    ensemble_models = []\n",
    "    ensemble_scalers_y = []\n",
    "    ensemble_scalers_X = []\n",
    "    all_test_predictions = []\n",
    "    \n",
    "    for model_idx in range(num_models):\n",
    "        print(f\"\\n--- Training Model {model_idx + 1}/{num_models} ---\")\n",
    "        \n",
    "        # Split for training (different random state for each model)\n",
    "        random_state = 42 + model_idx\n",
    "        \n",
    "        if use_series_info and series_ids_val is not None:\n",
    "            # Try stratified split, fall back to regular if not possible\n",
    "            try:\n",
    "                X_train_moe, X_val_moe, y_train_moe, y_val_moe, series_train, series_val = sklearn_train_test_split(\n",
    "                    X_val, y_val, series_ids_val, test_size=0.2, random_state=random_state, stratify=series_ids_val\n",
    "                )\n",
    "            except:\n",
    "                print(\"Stratified split failed, using regular split\")\n",
    "                X_train_moe, X_val_moe, y_train_moe, y_val_moe, series_train, series_val = sklearn_train_test_split(\n",
    "                    X_val, y_val, series_ids_val, test_size=0.2, random_state=random_state\n",
    "                )\n",
    "        else:\n",
    "            X_train_moe, X_val_moe, y_train_moe, y_val_moe = sklearn_train_test_split(\n",
    "                X_val, y_val, test_size=0.2, random_state=random_state\n",
    "            )\n",
    "            series_train = series_val = None\n",
    "        \n",
    "        # Scale features and targets\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        \n",
    "        X_train_moe_scaled = scaler_X.fit_transform(X_train_moe)\n",
    "        X_val_moe_scaled = scaler_X.transform(X_val_moe)\n",
    "        X_test_scaled = scaler_X.transform(X_test)\n",
    "        \n",
    "        y_train_moe_scaled = scaler_y.fit_transform(y_train_moe.reshape(-1, 1)).flatten()\n",
    "        y_val_moe_scaled = scaler_y.transform(y_val_moe.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = EnhancedTimeSeriesDataset(X_train_moe_scaled, y_train_moe_scaled, series_train)\n",
    "        val_dataset = EnhancedTimeSeriesDataset(X_val_moe_scaled, y_val_moe_scaled, series_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Initialize model\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        model = EnhancedMixtureOfExpertsAggregator(\n",
    "            num_experts=len(pred_columns),\n",
    "            num_series=num_series,\n",
    "            series_embed_dim=32 if num_series else 16,\n",
    "            hidden_dim=256,\n",
    "            dropout_rate=0.1,\n",
    "            use_series_info=use_series_info,\n",
    "            aggregation_method=aggregation_method\n",
    "        ).to(device)\n",
    "        \n",
    "        # Training setup\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2)\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        print(\"Starting training...\")\n",
    "        num_epochs = 300\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = train_enhanced_epoch(model, train_loader, criterion, optimizer, \n",
    "                                            device, use_series_info)\n",
    "            val_loss = validate_enhanced_epoch(model, val_loader, criterion, device, use_series_info)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(model.state_dict(), f'best_enhanced_moe_model_{model_idx}.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if epoch % 25 == 0:\n",
    "                print(f'Epoch {epoch:03d}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}')\n",
    "            \n",
    "            if patience_counter >= 40:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "        \n",
    "        # Load best model and make predictions\n",
    "        model.load_state_dict(torch.load(f'best_enhanced_moe_model_{model_idx}.pth'))\n",
    "        print(f'Model {model_idx + 1} - Best validation loss: {best_val_loss:.6f}')\n",
    "        \n",
    "        # Store model and scalers for ensemble\n",
    "        ensemble_models.append(model)\n",
    "        ensemble_scalers_y.append(scaler_y)\n",
    "        ensemble_scalers_X.append(scaler_X)\n",
    "        \n",
    "        # Get predictions from this model\n",
    "        test_predictions, test_gating_weights = predict_enhanced_moe(\n",
    "            model, X_test_scaled, series_ids_test, scaler_y, device, use_series_info\n",
    "        )\n",
    "        all_test_predictions.append(test_predictions)\n",
    "    \n",
    "    # Ensemble predictions (median of all models)\n",
    "    print(\"\\n--- Creating Ensemble Predictions ---\")\n",
    "    ensemble_test_predictions = np.median(np.array(all_test_predictions), axis=0)\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    test_preds_df_enhanced = test_preds_df.copy()\n",
    "    test_preds_df_enhanced['enhanced_moe_prediction'] = ensemble_test_predictions\n",
    "    \n",
    "    enhanced_moe_smape_test = calculate_smape_func(\n",
    "        y_test_df,\n",
    "        test_preds_df_enhanced,\n",
    "        'enhanced_moe_prediction'\n",
    "    )\n",
    "    \n",
    "    print(f\"Enhanced MoE Ensemble sMAPE on test set: {enhanced_moe_smape_test:.4f}\")\n",
    "    \n",
    "    # Compare with simple baselines\n",
    "    print(\"\\n--- Comparison with Baselines ---\")\n",
    "    \n",
    "    # Simple average and median\n",
    "    test_preds_df_enhanced['simple_avg'] = test_preds_df[pred_columns].mean(axis=1)\n",
    "    test_preds_df_enhanced['simple_median'] = test_preds_df[pred_columns].median(axis=1)\n",
    "    \n",
    "    simple_avg_smape = calculate_smape_func(y_test_df, test_preds_df_enhanced, 'simple_avg')\n",
    "    simple_median_smape = calculate_smape_func(y_test_df, test_preds_df_enhanced, 'simple_median')\n",
    "    \n",
    "    print(f\"Simple Average sMAPE: {simple_avg_smape:.4f}\")\n",
    "    print(f\"Simple Median sMAPE: {simple_median_smape:.4f}\")\n",
    "    print(f\"Enhanced MoE Ensemble sMAPE: {enhanced_moe_smape_test:.4f}\")\n",
    "    print(f\"Improvement over Average: {((simple_avg_smape - enhanced_moe_smape_test) / simple_avg_smape * 100):.2f}%\")\n",
    "    print(f\"Improvement over Median: {((simple_median_smape - enhanced_moe_smape_test) / simple_median_smape * 100):.2f}%\")\n",
    "    \n",
    "    # Analyze expert importance (using first model)\n",
    "    final_test_predictions, final_gating_weights = predict_enhanced_moe(\n",
    "        ensemble_models[0], ensemble_scalers_X[0].transform(X_test), \n",
    "        series_ids_test, ensemble_scalers_y[0], device, use_series_info\n",
    "    )\n",
    "    \n",
    "    avg_gating_weights = np.mean(final_gating_weights, axis=0)\n",
    "    expert_importance = dict(zip(pred_columns, avg_gating_weights))\n",
    "    expert_importance_sorted = sorted(expert_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\n--- Expert Importance (Average Gating Weights) ---\")\n",
    "    for expert, weight in expert_importance_sorted[:10]:  # Top 10\n",
    "        print(f\"{expert}: {weight:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    output_filename = f'enhanced_moe_predictions_{aggregation_method}_{\"with_series\" if use_series_info else \"no_series\"}.csv'\n",
    "    test_preds_df_enhanced.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nResults saved to: {output_filename}\")\n",
    "    \n",
    "    return {\n",
    "        'ensemble_models': ensemble_models,\n",
    "        'ensemble_scalers_X': ensemble_scalers_X,\n",
    "        'ensemble_scalers_y': ensemble_scalers_y,\n",
    "        'test_predictions': ensemble_test_predictions,\n",
    "        'test_smape': enhanced_moe_smape_test,\n",
    "        'expert_importance': expert_importance_sorted,\n",
    "        'predictions_df': test_preds_df_enhanced\n",
    "    }\n",
    "\n",
    "# ========== EASY-TO-USE WRAPPER FUNCTION ==========\n",
    "\n",
    "def run_enhanced_moe_training(val_preds_on_ensemble_18_models, preds_on_ensemble_18, \n",
    "                             y_test, calculate_smape):\n",
    "    \"\"\"\n",
    "    Easy wrapper function that matches your existing variable names\n",
    "    \"\"\"\n",
    "    print(\"Starting Enhanced MoE Training with your data...\")\n",
    "    \n",
    "    # Test different configurations\n",
    "    configurations = [\n",
    "        {'use_series_info': True, 'aggregation_method': 'robust_weighted'},\n",
    "        {'use_series_info': True, 'aggregation_method': 'weighted_median'},\n",
    "        {'use_series_info': False, 'aggregation_method': 'robust_weighted'},\n",
    "    ]\n",
    "    \n",
    "    best_config = None\n",
    "    best_smape = float('inf')\n",
    "    all_results = {}\n",
    "    \n",
    "    for i, config in enumerate(configurations):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"CONFIGURATION {i+1}: {config}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            results = train_enhanced_moe_complete(\n",
    "                val_preds_on_ensemble_18_models, \n",
    "                preds_on_ensemble_18, \n",
    "                y_test, \n",
    "                calculate_smape,\n",
    "                **config,\n",
    "                num_models=2  # Reduced for faster testing\n",
    "            )\n",
    "            \n",
    "            all_results[f\"config_{i+1}\"] = results\n",
    "            \n",
    "            if results['test_smape'] < best_smape:\n",
    "                best_smape = results['test_smape']\n",
    "                best_config = config\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Configuration {i+1} failed with error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Best configuration: {best_config}\")\n",
    "    print(f\"Best sMAPE: {best_smape:.4f}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# ========== USAGE INSTRUCTIONS ==========\n",
    "print(\"\"\"\n",
    "To run the enhanced MoE with your existing data, simply call:\n",
    "\n",
    "results = run_enhanced_moe_training(\n",
    "    val_preds_on_ensemble_18_models,  # Your validation predictions DataFrame\n",
    "    preds_on_ensemble_18,             # Your test predictions DataFrame  \n",
    "    y_test,                           # Your test targets DataFrame\n",
    "    calculate_smape                   # Your sMAPE calculation function\n",
    ")\n",
    "\n",
    "This will automatically:\n",
    "1. Test different configurations (with/without series info, different aggregation methods)\n",
    "2. Train ensemble models for each configuration\n",
    "3. Compare results and return the best performing setup\n",
    "4. Save all predictions to CSV files\n",
    "\n",
    "The function expects your DataFrames to have:\n",
    "- Prediction columns starting with 'NBeatsStackMoe'\n",
    "- 'y' column for targets (in validation data)\n",
    "- 'unique_id' column for series identification\n",
    "\"\"\")\n",
    "\n",
    "results = run_enhanced_moe_training(\n",
    "    val_preds_on_ensemble_18_models,  # Your validation predictions DataFrame\n",
    "    preds_on_ensemble_18,             # Your test predictions DataFrame  \n",
    "    y_test,                           # Your test targets DataFrame\n",
    "    calculate_smape                   # Your sMAPE calculation function\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
