{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-05 22:19:32,894\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-03-05 22:19:33,121\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasetsforecast.m3 import M3\n",
    "\n",
    "from models.auto.AutoTimeMoe import AutoTimeMoe\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\datasetsforecast\\m3.py:108: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(class_group.freq)\n"
     ]
    }
   ],
   "source": [
    "# load m3\n",
    "df = M3.load(\n",
    "            directory=\"C:\\\\Users\\\\ricar\\\\mixture_of_experts_time_series\\\\data\\\\m3\",\n",
    "            group=\"Monthly\")[0]\n",
    "\n",
    "def train_test_split(df: pd.DataFrame, horizon: int):\n",
    "    \"\"\"Split the dataframe into training and test sets by horizon.\"\"\"\n",
    "    groups = df.groupby('unique_id')\n",
    "    train_list, test_list = [], []\n",
    "    for _, group_df in groups:\n",
    "        group_df = group_df.sort_values('ds')\n",
    "        train_list.append(group_df.head(-horizon))\n",
    "        test_list.append(group_df.tail(horizon))\n",
    "    train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "    return train_df, test_df\n",
    "\n",
    "# df['ds'] = pd.to_datetime(df['ds']).astype(int)\n",
    "\n",
    "y_train_df, y_test_df = train_test_split(df, horizon=18)\n",
    "\n",
    "dataset, *_ = TimeSeriesDataset.from_df(y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:19:43,803] A new study created in memory with name: no-name-9bf44ea0-8c7b-4333-bcae-1f1f761f5535\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 11\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 9.2 K  | train\n",
      "5 | layers       | ModuleList            | 19.2 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 64     | train\n",
      "7 | output_layer | Linear                | 1.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "19.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.2 M    Total params\n",
      "76.910    Total estimated model params size (MB)\n",
      "49        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:  33%|███▎      | 2/6 [00:00<00:01,  2.66it/s, v_num=157, train_loss_step=2.45e+3, train_loss_epoch=2.91e+3, valid_loss=6.94e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:  33%|███▎      | 2/6 [00:00<00:01,  2.64it/s, v_num=157, train_loss_step=2.45e+3, train_loss_epoch=2.91e+3, valid_loss=6.94e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:20:09,572] Trial 0 finished with value: 69037.4921875 and parameters: {'hidden_size': 64, 'n_head': 2, 'learning_rate': 0.001776203019728038, 'scaler_type': 'robust', 'max_steps': 500, 'batch_size': 256, 'windows_batch_size': 128, 'intermediate_size': 20000, 'random_seed': 11, 'num_experts_per_tok': 1, 'num_experts': 4, 'input_size': 72, 'step_size': 1}. Best is trial 0 with value: 69037.4921875.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 10\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 16.3 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 64     | train\n",
      "7 | output_layer | Linear                | 1.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "16.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.3 M    Total params\n",
      "65.374    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166:  67%|██████▋   | 8/12 [00:01<00:00,  6.31it/s, v_num=158, train_loss_step=4.71e+5, train_loss_epoch=5.08e+5, valid_loss=1.33e+5] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166:  67%|██████▋   | 8/12 [00:01<00:00,  6.29it/s, v_num=158, train_loss_step=4.71e+5, train_loss_epoch=5.08e+5, valid_loss=1.33e+5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:22:40,613] Trial 1 finished with value: 132572.984375 and parameters: {'hidden_size': 64, 'n_head': 2, 'learning_rate': 0.0012668477913924615, 'scaler_type': None, 'max_steps': 2000, 'batch_size': 128, 'windows_batch_size': 128, 'intermediate_size': 5000, 'random_seed': 10, 'num_experts_per_tok': 1, 'num_experts': 16, 'input_size': 36, 'step_size': 18}. Best is trial 0 with value: 69037.4921875.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 11\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 46.1 K | train\n",
      "5 | layers       | ModuleList            | 138 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 256    | train\n",
      "7 | output_layer | Linear                | 4.6 K  | train\n",
      "---------------------------------------------------------------\n",
      "138 M     Trainable params\n",
      "0         Non-trainable params\n",
      "138 M     Total params\n",
      "554.235   Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:  44%|████▍     | 20/45 [00:02<00:03,  7.26it/s, v_num=159, train_loss_step=1.92e+5, train_loss_epoch=2.01e+5, valid_loss=5.58e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:  44%|████▍     | 20/45 [00:02<00:03,  7.25it/s, v_num=159, train_loss_step=1.92e+5, train_loss_epoch=2.01e+5, valid_loss=5.58e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:28:10,378] Trial 2 finished with value: 55552.53515625 and parameters: {'hidden_size': 256, 'n_head': 2, 'learning_rate': 0.009518923937569385, 'scaler_type': None, 'max_steps': 2000, 'batch_size': 32, 'windows_batch_size': 128, 'intermediate_size': 20000, 'random_seed': 11, 'num_experts_per_tok': 2, 'num_experts': 16, 'input_size': 90, 'step_size': 1}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 6\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 55.3 K | train\n",
      "5 | layers       | ModuleList            | 39.5 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 512    | train\n",
      "7 | output_layer | Linear                | 9.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "39.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "39.5 M    Total params\n",
      "158.099   Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:04,  7.53it/s, v_num=160, train_loss_step=1.66e+5, train_loss_epoch=1.95e+5, valid_loss=5.61e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:04,  7.52it/s, v_num=160, train_loss_step=1.66e+5, train_loss_epoch=1.95e+5, valid_loss=5.61e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:29:44,301] Trial 3 finished with value: 55914.890625 and parameters: {'hidden_size': 512, 'n_head': 2, 'learning_rate': 0.009812552811843785, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 32, 'windows_batch_size': 128, 'intermediate_size': 5000, 'random_seed': 6, 'num_experts_per_tok': 4, 'num_experts': 16, 'input_size': 54, 'step_size': 18}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 17\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 92.2 K | train\n",
      "5 | layers       | ModuleList            | 8.7 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 512    | train\n",
      "7 | output_layer | Linear                | 9.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "8.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 M     Total params\n",
      "35.351    Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:  48%|████▊     | 11/23 [00:00<00:01, 11.19it/s, v_num=161, train_loss_step=1.59e+6, train_loss_epoch=1.57e+6, valid_loss=5.68e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:  48%|████▊     | 11/23 [00:00<00:01, 11.16it/s, v_num=161, train_loss_step=1.59e+6, train_loss_epoch=1.57e+6, valid_loss=5.68e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:30:35,134] Trial 4 finished with value: 56628.95703125 and parameters: {'hidden_size': 512, 'n_head': 4, 'learning_rate': 0.05369725265760247, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 64, 'windows_batch_size': 1024, 'intermediate_size': 1000, 'random_seed': 17, 'num_experts_per_tok': 2, 'num_experts': 8, 'input_size': 90, 'step_size': 18}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 12\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 18.4 K | train\n",
      "5 | layers       | ModuleList            | 154 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 512    | train\n",
      "7 | output_layer | Linear                | 9.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "154 M     Trainable params\n",
      "0         Non-trainable params\n",
      "154 M     Total params\n",
      "618.727   Total estimated model params size (MB)\n",
      "49        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  11%|█         | 5/45 [00:01<00:10,  3.79it/s, v_num=162, train_loss_step=8.91e+3, train_loss_epoch=1.76e+4, valid_loss=6.87e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  11%|█         | 5/45 [00:01<00:10,  3.78it/s, v_num=162, train_loss_step=8.91e+3, train_loss_epoch=1.76e+4, valid_loss=6.87e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:32:03,706] Trial 5 finished with value: 68351.109375 and parameters: {'hidden_size': 512, 'n_head': 8, 'learning_rate': 0.0948272640829195, 'scaler_type': 'standard', 'max_steps': 500, 'batch_size': 32, 'windows_batch_size': 256, 'intermediate_size': 20000, 'random_seed': 12, 'num_experts_per_tok': 1, 'num_experts': 4, 'input_size': 18, 'step_size': 18}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 2\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 11.5 K | train\n",
      "5 | layers       | ModuleList            | 9.6 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 64     | train\n",
      "7 | output_layer | Linear                | 1.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "9.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.6 M     Total params\n",
      "38.522    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  11%|█         | 5/45 [00:01<00:14,  2.79it/s, v_num=163, train_loss_step=3.32e+4, train_loss_epoch=3.21e+4, valid_loss=7.02e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  11%|█         | 5/45 [00:01<00:14,  2.78it/s, v_num=163, train_loss_step=3.32e+4, train_loss_epoch=3.21e+4, valid_loss=7.02e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:32:45,429] Trial 6 finished with value: 69828.078125 and parameters: {'hidden_size': 64, 'n_head': 2, 'learning_rate': 0.00017528824554993602, 'scaler_type': 'robust', 'max_steps': 500, 'batch_size': 32, 'windows_batch_size': 512, 'intermediate_size': 10000, 'random_seed': 2, 'num_experts_per_tok': 4, 'num_experts': 16, 'input_size': 90, 'step_size': 18}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 16\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 11.5 K | train\n",
      "5 | layers       | ModuleList            | 977 K  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 64     | train\n",
      "7 | output_layer | Linear                | 1.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "990 K     Trainable params\n",
      "0         Non-trainable params\n",
      "990 K     Total params\n",
      "3.960     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333:  33%|███▎      | 2/6 [00:00<00:01,  2.09it/s, v_num=164, train_loss_step=1.29e+4, train_loss_epoch=9.5e+3, valid_loss=7.13e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333:  33%|███▎      | 2/6 [00:00<00:01,  2.09it/s, v_num=164, train_loss_step=1.29e+4, train_loss_epoch=9.5e+3, valid_loss=7.13e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:34:34,406] Trial 7 finished with value: 70906.25 and parameters: {'hidden_size': 64, 'n_head': 2, 'learning_rate': 0.016789193949549253, 'scaler_type': 'standard', 'max_steps': 2000, 'batch_size': 256, 'windows_batch_size': 512, 'intermediate_size': 1000, 'random_seed': 16, 'num_experts_per_tok': 2, 'num_experts': 8, 'input_size': 90, 'step_size': 1}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 19\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 73.7 K | train\n",
      "5 | layers       | ModuleList            | 2.4 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 512    | train\n",
      "7 | output_layer | Linear                | 9.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.086    Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166:  67%|██████▋   | 8/12 [00:00<00:00,  8.43it/s, v_num=165, train_loss_step=1.07e+4, train_loss_epoch=1.4e+4, valid_loss=7.16e+4]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166:  67%|██████▋   | 8/12 [00:00<00:00,  8.40it/s, v_num=165, train_loss_step=1.07e+4, train_loss_epoch=1.4e+4, valid_loss=7.16e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:36:10,151] Trial 8 finished with value: 71219.4140625 and parameters: {'hidden_size': 512, 'n_head': 4, 'learning_rate': 0.0002708796324449542, 'scaler_type': 'standard', 'max_steps': 2000, 'batch_size': 128, 'windows_batch_size': 256, 'intermediate_size': 100, 'random_seed': 19, 'num_experts_per_tok': 1, 'num_experts': 8, 'input_size': 72, 'step_size': 18}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 15\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 55.3 K | train\n",
      "5 | layers       | ModuleList            | 2.4 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 512    | train\n",
      "7 | output_layer | Linear                | 9.2 K  | train\n",
      "---------------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.029    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333:  33%|███▎      | 2/6 [00:01<00:02,  1.59it/s, v_num=166, train_loss_step=8.77e+3, train_loss_epoch=6.35e+3, valid_loss=6.78e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333:  33%|███▎      | 2/6 [00:01<00:02,  1.59it/s, v_num=166, train_loss_step=8.77e+3, train_loss_epoch=6.35e+3, valid_loss=6.78e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:38:24,249] Trial 9 finished with value: 67453.4921875 and parameters: {'hidden_size': 512, 'n_head': 4, 'learning_rate': 0.008439587836749744, 'scaler_type': 'robust', 'max_steps': 2000, 'batch_size': 256, 'windows_batch_size': 128, 'intermediate_size': 100, 'random_seed': 15, 'num_experts_per_tok': 2, 'num_experts': 16, 'input_size': 54, 'step_size': 18}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 6\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 18.4 K | train\n",
      "5 | layers       | ModuleList            | 138 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 256    | train\n",
      "7 | output_layer | Linear                | 4.6 K  | train\n",
      "---------------------------------------------------------------\n",
      "138 M     Trainable params\n",
      "0         Non-trainable params\n",
      "138 M     Total params\n",
      "554.124   Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86:  96%|█████████▌| 22/23 [00:12<00:00,  1.71it/s, v_num=167, train_loss_step=2.45e+6, train_loss_epoch=2.63e+6, valid_loss=9.09e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86:  96%|█████████▌| 22/23 [00:12<00:00,  1.71it/s, v_num=167, train_loss_step=2.45e+6, train_loss_epoch=2.63e+6, valid_loss=9.09e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:47:15,598] Trial 10 finished with value: 90706.515625 and parameters: {'hidden_size': 256, 'n_head': 8, 'learning_rate': 0.0009916027591403158, 'scaler_type': None, 'max_steps': 2000, 'batch_size': 64, 'windows_batch_size': 1024, 'intermediate_size': 20000, 'random_seed': 6, 'num_experts_per_tok': 2, 'num_experts': 16, 'input_size': 36, 'step_size': 1}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 6\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 27.6 K | train\n",
      "5 | layers       | ModuleList            | 19.5 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 256    | train\n",
      "7 | output_layer | Linear                | 4.6 K  | train\n",
      "---------------------------------------------------------------\n",
      "19.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.5 M    Total params\n",
      "78.001    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:06,  5.12it/s, v_num=168, train_loss_step=1.58e+5, train_loss_epoch=1.86e+5, valid_loss=5.6e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:06,  5.12it/s, v_num=168, train_loss_step=1.58e+5, train_loss_epoch=1.86e+5, valid_loss=5.6e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:48:23,305] Trial 11 finished with value: 55833.96484375 and parameters: {'hidden_size': 256, 'n_head': 2, 'learning_rate': 0.007547271906974293, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 32, 'windows_batch_size': 128, 'intermediate_size': 5000, 'random_seed': 6, 'num_experts_per_tok': 4, 'num_experts': 16, 'input_size': 54, 'step_size': 1}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 7\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 27.6 K | train\n",
      "5 | layers       | ModuleList            | 19.5 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 256    | train\n",
      "7 | output_layer | Linear                | 4.6 K  | train\n",
      "---------------------------------------------------------------\n",
      "19.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.5 M    Total params\n",
      "78.001    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:06,  5.17it/s, v_num=169, train_loss_step=1.71e+5, train_loss_epoch=2.02e+5, valid_loss=5.6e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:06,  5.17it/s, v_num=169, train_loss_step=1.71e+5, train_loss_epoch=2.02e+5, valid_loss=5.6e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:49:49,629] Trial 12 finished with value: 55783.89453125 and parameters: {'hidden_size': 256, 'n_head': 2, 'learning_rate': 0.004461274952585403, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 32, 'windows_batch_size': 128, 'intermediate_size': 5000, 'random_seed': 7, 'num_experts_per_tok': 4, 'num_experts': 16, 'input_size': 54, 'step_size': 1}. Best is trial 2 with value: 55552.53515625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 9\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 19.3 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 128    | train\n",
      "7 | output_layer | Linear                | 2.3 K  | train\n",
      "---------------------------------------------------------------\n",
      "19.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.3 M    Total params\n",
      "77.102    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:04,  7.58it/s, v_num=170, train_loss_step=2.06e+5, train_loss_epoch=2.09e+5, valid_loss=5.57e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:04,  7.56it/s, v_num=170, train_loss_step=2.06e+5, train_loss_epoch=2.09e+5, valid_loss=5.57e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:50:58,697] Trial 13 finished with value: 55456.77734375 and parameters: {'hidden_size': 128, 'n_head': 2, 'learning_rate': 0.025517294617549806, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 32, 'windows_batch_size': 128, 'intermediate_size': 10000, 'random_seed': 9, 'num_experts_per_tok': 4, 'num_experts': 16, 'input_size': 18, 'step_size': 1}. Best is trial 13 with value: 55456.77734375.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 9\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 19.3 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 128    | train\n",
      "7 | output_layer | Linear                | 2.3 K  | train\n",
      "---------------------------------------------------------------\n",
      "19.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.3 M    Total params\n",
      "77.102    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:05,  7.00it/s, v_num=171, train_loss_step=2.06e+5, train_loss_epoch=2.09e+5, valid_loss=5.57e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:05,  6.98it/s, v_num=171, train_loss_step=2.06e+5, train_loss_epoch=2.09e+5, valid_loss=5.57e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:52:06,032] Trial 14 finished with value: 55420.65625 and parameters: {'hidden_size': 128, 'n_head': 2, 'learning_rate': 0.03112913780246651, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 32, 'windows_batch_size': 128, 'intermediate_size': 10000, 'random_seed': 9, 'num_experts_per_tok': 4, 'num_experts': 16, 'input_size': 18, 'step_size': 1}. Best is trial 14 with value: 55420.65625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 2\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 7.7 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 128    | train\n",
      "7 | output_layer | Linear                | 2.3 K  | train\n",
      "---------------------------------------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.015    Total estimated model params size (MB)\n",
      "49        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:00<00:02, 13.25it/s, v_num=172, train_loss_step=1.85e+5, train_loss_epoch=1.86e+5, valid_loss=5.61e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:00<00:02, 13.22it/s, v_num=172, train_loss_step=1.85e+5, train_loss_epoch=1.86e+5, valid_loss=5.61e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:52:52,959] Trial 15 finished with value: 55845.3984375 and parameters: {'hidden_size': 128, 'n_head': 8, 'learning_rate': 0.03157854797202344, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 32, 'windows_batch_size': 128, 'intermediate_size': 10000, 'random_seed': 2, 'num_experts_per_tok': 4, 'num_experts': 4, 'input_size': 18, 'step_size': 1}. Best is trial 14 with value: 55420.65625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 9\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 19.3 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 128    | train\n",
      "7 | output_layer | Linear                | 2.3 K  | train\n",
      "---------------------------------------------------------------\n",
      "19.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.3 M    Total params\n",
      "77.102    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:04,  7.76it/s, v_num=173, train_loss_step=8.34e+5, train_loss_epoch=8.29e+5, valid_loss=5.57e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:04,  7.75it/s, v_num=173, train_loss_step=8.34e+5, train_loss_epoch=8.29e+5, valid_loss=5.57e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:54:03,668] Trial 16 finished with value: 55491.1015625 and parameters: {'hidden_size': 128, 'n_head': 2, 'learning_rate': 0.028569446264915463, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 32, 'windows_batch_size': 512, 'intermediate_size': 10000, 'random_seed': 9, 'num_experts_per_tok': 4, 'num_experts': 16, 'input_size': 18, 'step_size': 1}. Best is trial 14 with value: 55420.65625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 13\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 19.3 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 128    | train\n",
      "7 | output_layer | Linear                | 2.3 K  | train\n",
      "---------------------------------------------------------------\n",
      "19.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.3 M    Total params\n",
      "77.102    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:  48%|████▊     | 11/23 [00:01<00:01,  7.35it/s, v_num=174, train_loss_step=1.6e+6, train_loss_epoch=1.54e+6, valid_loss=5.63e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:  48%|████▊     | 11/23 [00:01<00:01,  7.33it/s, v_num=174, train_loss_step=1.6e+6, train_loss_epoch=1.54e+6, valid_loss=5.63e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:55:36,041] Trial 17 finished with value: 56094.16796875 and parameters: {'hidden_size': 128, 'n_head': 2, 'learning_rate': 0.07681810930504247, 'scaler_type': None, 'max_steps': 1000, 'batch_size': 64, 'windows_batch_size': 1024, 'intermediate_size': 10000, 'random_seed': 13, 'num_experts_per_tok': 4, 'num_experts': 16, 'input_size': 18, 'step_size': 1}. Best is trial 14 with value: 55420.65625.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 8\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 7.7 M  | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 128    | train\n",
      "7 | output_layer | Linear                | 2.3 K  | train\n",
      "---------------------------------------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.015    Total estimated model params size (MB)\n",
      "49        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:  33%|███▎      | 4/12 [00:00<00:01,  5.31it/s, v_num=175, train_loss_step=7.19e+3, train_loss_epoch=3.64e+3, valid_loss=6.61e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:  33%|███▎      | 4/12 [00:00<00:01,  5.28it/s, v_num=175, train_loss_step=7.19e+3, train_loss_epoch=3.64e+3, valid_loss=6.61e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:56:37,410] Trial 18 finished with value: 65829.1796875 and parameters: {'hidden_size': 128, 'n_head': 4, 'learning_rate': 0.028351597985669517, 'scaler_type': 'robust', 'max_steps': 1000, 'batch_size': 128, 'windows_batch_size': 256, 'intermediate_size': 10000, 'random_seed': 8, 'num_experts_per_tok': 4, 'num_experts': 4, 'input_size': 18, 'step_size': 1}. Best is trial 14 with value: 55420.65625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_auto.py:291: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  v = trial.suggest_loguniform(k, v.lower, v.upper)\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 5\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 11.6 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 128    | train\n",
      "7 | output_layer | Linear                | 2.3 K  | train\n",
      "---------------------------------------------------------------\n",
      "11.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 M    Total params\n",
      "46.377    Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:05,  6.32it/s, v_num=176, train_loss_step=1.61e+3, train_loss_epoch=1.77e+3, valid_loss=6.83e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:05,  6.31it/s, v_num=176, train_loss_step=1.61e+3, train_loss_epoch=1.77e+3, valid_loss=6.83e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-05 22:57:30,028] Trial 19 finished with value: 67981.5546875 and parameters: {'hidden_size': 128, 'n_head': 8, 'learning_rate': 0.0032655891308713755, 'scaler_type': 'standard', 'max_steps': 1000, 'batch_size': 32, 'windows_batch_size': 128, 'intermediate_size': 10000, 'random_seed': 5, 'num_experts_per_tok': 4, 'num_experts': 8, 'input_size': 18, 'step_size': 1}. Best is trial 14 with value: 55420.65625.\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 9\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type                  | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | loss         | MAE                   | 0      | train\n",
      "1 | padder_train | ConstantPad1d         | 0      | train\n",
      "2 | scaler       | TemporalNorm          | 0      | train\n",
      "3 | dropout      | Dropout               | 0      | train\n",
      "4 | embed_layer  | TimeMoeInputEmbedding | 4.6 K  | train\n",
      "5 | layers       | ModuleList            | 19.3 M | train\n",
      "6 | norm         | TimeMoeRMSNorm        | 128    | train\n",
      "7 | output_layer | Linear                | 2.3 K  | train\n",
      "---------------------------------------------------------------\n",
      "19.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.3 M    Total params\n",
      "77.102    Total estimated model params size (MB)\n",
      "109       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:03,  9.91it/s, v_num=177, train_loss_step=1.89e+5, train_loss_epoch=2.1e+5] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:01<00:03,  9.88it/s, v_num=177, train_loss_step=1.89e+5, train_loss_epoch=2.1e+5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoTimeMoe"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoTimeMoe(h=18, num_samples=20, backend=\"optuna\")\n",
    "\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model config\n",
    "test_dataset, *_ = TimeSeriesDataset.from_df(y_test_df)\n",
    "\n",
    "y_hat = model.predict(dataset=test_dataset)\n",
    "\n",
    "y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
