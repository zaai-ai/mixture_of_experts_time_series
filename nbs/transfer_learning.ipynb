{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89e25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c9a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-17 01:31:34,308\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-04-17 01:31:34,466\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\gluonts\\json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.models import NBEATS\n",
    "from neuralforecast import NeuralForecast\n",
    "from utils import load_dataset, train_test_split\n",
    "from models.NBeatsMoe import NBeatsMoe, NBEATSMoEBlock\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "# datasets list\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"gluonts_tourism_monthly\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"m3\",\n",
    "        \"directory\": \"C:\\\\Users\\\\ricar\\\\mixture_of_experts_time_series\\\\data\\\\m3\\\\\",\n",
    "        \"group\": \"Monthly\",\n",
    "        \"freq\": \"M\",\n",
    "    } \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using dataset already processed in path C:\\Users\\ricar\\.gluonts\\datasets\\tourism_monthly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tourism_monthly dataset...\n",
      "Loading m3_monthly dataset...\n"
     ]
    }
   ],
   "source": [
    "Y_ALL_tourism, horizon, n_lags, group, _ = load_dataset(\"gluonts_tourism_monthly\", datasets[0])\n",
    "Y_ALL_m3 = load_dataset(\"m3\", datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af984ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(n_lags)\n",
    "Y_train_df_tourism, Y_test_df_tourism = train_test_split(Y_ALL_tourism, horizon)\n",
    "Y_train_df_m3, Y_test_df_m3 = train_test_split(Y_ALL_m3, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "models_tourism = NBEATS(h=horizon, input_size=n_lags)\n",
    "models_m3 = NBEATS(h=horizon, input_size=n_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e37352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "1.6 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.853     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:  33%|███▎      | 4/12 [00:01<00:02,  3.61it/s, v_num=68, train_loss_step=1.15e+3, train_loss_epoch=893.0, valid_loss=2.65e+3]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:  33%|███▎      | 4/12 [00:01<00:02,  3.61it/s, v_num=68, train_loss_step=1.15e+3, train_loss_epoch=893.0, valid_loss=2.65e+3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "1.6 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.853     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:02<00:07,  4.74it/s, v_num=69, train_loss_step=488.0, train_loss_epoch=579.0, valid_loss=665.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:02<00:07,  4.74it/s, v_num=69, train_loss_step=488.0, train_loss_epoch=579.0, valid_loss=665.0]\n"
     ]
    }
   ],
   "source": [
    "fcst_tourism = NeuralForecast(models=[models_tourism], freq=\"M\")\n",
    "fcst_tourism.fit(df=Y_train_df_tourism, static_df=None, val_size=horizon)\n",
    "\n",
    "fcst_m3 = NeuralForecast(models=[models_m3], freq=\"M\")\n",
    "fcst_m3.fit(df=Y_train_df_m3, static_df=None, val_size=horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7c061",
   "metadata": {},
   "source": [
    "Now lets add the 2 datasets together ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eacd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "blcs_tourism = fcst_tourism.models[0].blocks\n",
    "blcs_m3 = fcst_m3.models[0].blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bfc10",
   "metadata": {},
   "source": [
    "... and the 2 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade93070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): NBEATSMoEBlock(\n",
       "    (experts): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (6): ReLU()\n",
       "        (7): Linear(in_features=512, out_features=42, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gate): Sequential(\n",
       "      (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=24, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): Linear(in_features=16, out_features=42, bias=True)\n",
       "    )\n",
       "    (pooling): SparsePooling(\n",
       "      (experts): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (6): ReLU()\n",
       "          (7): Linear(in_features=512, out_features=42, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): Sequential(\n",
       "        (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (basis): IdentityBasis()\n",
       "  )\n",
       "  (1): NBEATSMoEBlock(\n",
       "    (experts): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (6): ReLU()\n",
       "        (7): Linear(in_features=512, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gate): Sequential(\n",
       "      (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=24, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): Linear(in_features=16, out_features=6, bias=True)\n",
       "    )\n",
       "    (pooling): SparsePooling(\n",
       "      (experts): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (6): ReLU()\n",
       "          (7): Linear(in_features=512, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): Sequential(\n",
       "        (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (basis): TrendBasis()\n",
       "  )\n",
       "  (2): NBEATSMoEBlock(\n",
       "    (experts): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (6): ReLU()\n",
       "        (7): Linear(in_features=512, out_features=68, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gate): Sequential(\n",
       "      (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=24, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): Linear(in_features=16, out_features=68, bias=True)\n",
       "    )\n",
       "    (pooling): SparsePooling(\n",
       "      (experts): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (6): ReLU()\n",
       "          (7): Linear(in_features=512, out_features=68, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): Sequential(\n",
       "        (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (basis): SeasonalityBasis()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_layers = nn.ModuleList()\n",
    "for i in zip(blcs_tourism, blcs_m3):\n",
    "    blc1, blc2 = i\n",
    "    n_theta = blc1.layers[-1].out_features\n",
    "    added_layers.append(NBEATSMoEBlock(\n",
    "        input_size=n_lags,\n",
    "        top_k=1,\n",
    "        nr_experts=2,\n",
    "        n_theta=n_theta,\n",
    "        mlp_units=[[16,16], [16,16], [16,16]], ## just moked\n",
    "        basis=blc1.basis,\n",
    "        activation=\"ReLU\",\n",
    "        dropout_prob=blc1.dropout_prob,\n",
    "        pre_experts=nn.ModuleList([blc1.layers, blc2.layers]),\n",
    "    ))\n",
    "added_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "moe = NBeatsMoe(\n",
    "    pre_blocks=added_layers,\n",
    "    nr_experts=2,\n",
    "    top_k=1,\n",
    "    input_size=n_lags,\n",
    "    h=horizon,\n",
    "    # learning_rate=1e-5,\n",
    "    # max_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a23d1",
   "metadata": {},
   "source": [
    "Let's train ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add both y_all\n",
    "Y_ALL = Y_ALL_tourism.copy()\n",
    "Y_ALL = pd.concat([Y_ALL, Y_ALL_m3], ignore_index=True)\n",
    "\n",
    "# split train and test\n",
    "Y_train_df, Y_test_df = train_test_split(Y_ALL, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6165b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 4.9 M  | train\n",
      "-------------------------------------------------------\n",
      "4.9 M     Trainable params\n",
      "1.6 K     Non-trainable params\n",
      "4.9 M     Total params\n",
      "19.724    Total estimated model params size (MB)\n",
      "97        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]expert_output: torch.Size([32, 42])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 42])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 6])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 6])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 68])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 68])\n",
      "expert_weight: torch.Size([32])\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 45.49it/s]expert_output: torch.Size([32, 42])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 42])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 6])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 6])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 68])\n",
      "expert_weight: torch.Size([32])\n",
      "expert_output: torch.Size([32, 68])\n",
      "expert_weight: torch.Size([32])\n",
      "Epoch 0:   0%|          | 0/57 [00:00<?, ?it/s]                            expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:   2%|▏         | 1/57 [00:00<00:09,  5.72it/s, v_num=72, train_loss_step=2.83e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:   4%|▎         | 2/57 [00:00<00:08,  6.12it/s, v_num=72, train_loss_step=2.34e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:   5%|▌         | 3/57 [00:00<00:08,  6.13it/s, v_num=72, train_loss_step=840.0]  expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:   7%|▋         | 4/57 [00:00<00:08,  6.12it/s, v_num=72, train_loss_step=669.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:   9%|▉         | 5/57 [00:00<00:08,  6.12it/s, v_num=72, train_loss_step=794.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  11%|█         | 6/57 [00:00<00:08,  6.27it/s, v_num=72, train_loss_step=785.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  12%|█▏        | 7/57 [00:01<00:08,  6.24it/s, v_num=72, train_loss_step=463.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  14%|█▍        | 8/57 [00:01<00:07,  6.21it/s, v_num=72, train_loss_step=712.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  16%|█▌        | 9/57 [00:01<00:07,  6.25it/s, v_num=72, train_loss_step=573.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  18%|█▊        | 10/57 [00:01<00:07,  6.28it/s, v_num=72, train_loss_step=673.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  19%|█▉        | 11/57 [00:01<00:07,  6.27it/s, v_num=72, train_loss_step=1.16e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  21%|██        | 12/57 [00:01<00:07,  6.27it/s, v_num=72, train_loss_step=695.0]  expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  23%|██▎       | 13/57 [00:02<00:06,  6.31it/s, v_num=72, train_loss_step=535.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  25%|██▍       | 14/57 [00:02<00:06,  6.30it/s, v_num=72, train_loss_step=537.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  26%|██▋       | 15/57 [00:02<00:06,  6.27it/s, v_num=72, train_loss_step=695.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  28%|██▊       | 16/57 [00:02<00:06,  6.23it/s, v_num=72, train_loss_step=932.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  30%|██▉       | 17/57 [00:02<00:06,  6.22it/s, v_num=72, train_loss_step=757.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  32%|███▏      | 18/57 [00:02<00:06,  6.21it/s, v_num=72, train_loss_step=2.4e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  33%|███▎      | 19/57 [00:03<00:06,  6.19it/s, v_num=72, train_loss_step=1.73e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  35%|███▌      | 20/57 [00:03<00:05,  6.18it/s, v_num=72, train_loss_step=688.0]  expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  37%|███▋      | 21/57 [00:03<00:05,  6.21it/s, v_num=72, train_loss_step=938.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  39%|███▊      | 22/57 [00:03<00:05,  6.23it/s, v_num=72, train_loss_step=676.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  40%|████      | 23/57 [00:03<00:05,  6.25it/s, v_num=72, train_loss_step=334.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  42%|████▏     | 24/57 [00:03<00:05,  6.23it/s, v_num=72, train_loss_step=717.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  44%|████▍     | 25/57 [00:03<00:05,  6.26it/s, v_num=72, train_loss_step=2.16e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  46%|████▌     | 26/57 [00:04<00:04,  6.26it/s, v_num=72, train_loss_step=810.0]  expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  47%|████▋     | 27/57 [00:04<00:04,  6.26it/s, v_num=72, train_loss_step=467.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  49%|████▉     | 28/57 [00:04<00:04,  6.26it/s, v_num=72, train_loss_step=568.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  51%|█████     | 29/57 [00:04<00:04,  6.26it/s, v_num=72, train_loss_step=651.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  53%|█████▎    | 30/57 [00:04<00:04,  6.25it/s, v_num=72, train_loss_step=3.31e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  54%|█████▍    | 31/57 [00:04<00:04,  6.27it/s, v_num=72, train_loss_step=2.08e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  56%|█████▌    | 32/57 [00:05<00:03,  6.28it/s, v_num=72, train_loss_step=783.0]  expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  58%|█████▊    | 33/57 [00:05<00:03,  6.30it/s, v_num=72, train_loss_step=1.42e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  60%|█████▉    | 34/57 [00:05<00:03,  6.30it/s, v_num=72, train_loss_step=1.02e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  61%|██████▏   | 35/57 [00:05<00:03,  6.30it/s, v_num=72, train_loss_step=909.0]  expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  63%|██████▎   | 36/57 [00:05<00:03,  6.30it/s, v_num=72, train_loss_step=2.15e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  65%|██████▍   | 37/57 [00:05<00:03,  6.29it/s, v_num=72, train_loss_step=528.0]  expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  67%|██████▋   | 38/57 [00:06<00:03,  6.30it/s, v_num=72, train_loss_step=2.07e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  68%|██████▊   | 39/57 [00:06<00:02,  6.31it/s, v_num=72, train_loss_step=3.12e+3]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  70%|███████   | 40/57 [00:06<00:02,  6.31it/s, v_num=72, train_loss_step=357.0]  expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "Epoch 0:  72%|███████▏  | 41/57 [00:06<00:02,  6.31it/s, v_num=72, train_loss_step=721.0]expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 42])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 6])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n",
      "expert_output: torch.Size([1024, 68])\n",
      "expert_weight: torch.Size([1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    571\u001b[0m     ckpt_path,\n\u001b[0;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1026\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:171\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 171\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1302\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 223\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:323\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 323\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_windows.py:432\u001b[0m, in \u001b[0;36mBaseWindows.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutsample_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutsample_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss):\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\losses\\pytorch.py:133\u001b[0m, in \u001b[0;36mMAE.__call__\u001b[1;34m(self, y, y_hat, mask)\u001b[0m\n\u001b[0;32m    132\u001b[0m losses \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(y \u001b[38;5;241m-\u001b[39m y_hat)\n\u001b[1;32m--> 133\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _weighted_mean(losses\u001b[38;5;241m=\u001b[39mlosses, weights\u001b[38;5;241m=\u001b[39mweights)\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\losses\\pytorch.py:91\u001b[0m, in \u001b[0;36mBasePointLoss._compute_weights\u001b[1;34m(self, y, mask)\u001b[0m\n\u001b[0;32m     90\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhorizon_weight\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m---> 91\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(mask, device\u001b[38;5;241m=\u001b[39mmask\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m \u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights \u001b[38;5;241m*\u001b[39m mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m fcts_tl \u001b[38;5;241m=\u001b[39m NeuralForecast(models\u001b[38;5;241m=\u001b[39m[moe], freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfcts_tl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhorizon\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\core.py:547\u001b[0m, in \u001b[0;36mNeuralForecast.fit\u001b[1;34m(self, df, static_df, val_size, use_init_models, verbose, id_col, time_col, target_col, distributed_config, prediction_intervals)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_models()\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels):\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributed_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_config\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_windows.py:661\u001b[0m, in \u001b[0;36mBaseWindows.fit\u001b[1;34m(self, dataset, val_size, test_size, random_seed, distributed_config)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    634\u001b[0m     dataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    638\u001b[0m     distributed_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    639\u001b[0m ):\n\u001b[0;32m    640\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit.\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m    The `fit` method, optimizes the neural network's weights using the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;124;03m    `test_size`: int, test size for temporal cross-validation.<br>\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistributed_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\common\\_base_model.py:360\u001b[0m, in \u001b[0;36mBaseModel._fit\u001b[1;34m(self, dataset, batch_size, valid_batch_size, val_size, test_size, random_seed, shuffle_train, distributed_config)\u001b[0m\n\u001b[0;32m    358\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    359\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrainer_kwargs)\n\u001b[1;32m--> 360\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m model\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcallback_metrics\n\u001b[0;32m    362\u001b[0m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "fcts_tl = NeuralForecast(models=[moe], freq=\"M\")\n",
    "fcts_tl.fit(df=Y_train_df, static_df=None, val_size=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 57/57 [00:01<00:00, 54.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 77.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 45/45 [00:00<00:00, 87.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# lets predict ...\n",
    "predictions = fcts_tl.predict(futr_df=Y_test_df)\n",
    "predictions_tourism = fcst_tourism.predict(futr_df=Y_test_df_tourism)\n",
    "predictions_m3 = fcst_m3.predict(futr_df=Y_test_df_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12deffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl: 0.2238958588898837\n",
      "SMAPE for fcst_tourism: 0.24402993926027292\n",
      "SMAPE for fcst_m3: 0.13870548088695284\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.losses.numpy import smape\n",
    "\n",
    "# Calculate SMAPE for each prediction\n",
    "\n",
    "# For predictions from fcts_tl\n",
    "def calculate_smape(Y_test, predictions, model_name):\n",
    "    y_true = Y_test['y'].values\n",
    "    y_hat = predictions[model_name].values\n",
    "\n",
    "    n_series = Y_test['unique_id'].nunique()\n",
    "    y_true = y_true.reshape(n_series, -1)\n",
    "    y_hat = y_hat.reshape(n_series, -1)\n",
    "\n",
    "    smape_value = smape(y_true, y_hat)\n",
    "    return smape_value\n",
    "\n",
    "# Calculate SMAPE for fcts_tl\n",
    "smape_tl = calculate_smape(Y_test_df, predictions, moe.__class__.__name__)\n",
    "smape_tourism = calculate_smape(Y_test_df_tourism, predictions_tourism, \"NBEATS\")\n",
    "smape_m3 = calculate_smape(Y_test_df_m3, predictions_m3, \"NBEATS\")\n",
    "\n",
    "# Print SMAPE values\n",
    "print(f\"SMAPE for fcts_tl: {smape_tl}\")\n",
    "print(f\"SMAPE for fcst_tourism: {smape_tourism}\")\n",
    "print(f\"SMAPE for fcst_m3: {smape_m3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d989320",
   "metadata": {},
   "source": [
    "Test the moe on both datasets independently ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f37fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl_tourism: 0.4129302430484678\n",
      "SMAPE for fcts_tl_m3: 0.1754458696727676\n"
     ]
    }
   ],
   "source": [
    "predictions_tl_tourism = predictions[~predictions['unique_id'].str.match(r'^M\\d+')]\n",
    "predictions_tl_m3 = predictions[predictions['unique_id'].str.match(r'^M\\d+')]\n",
    "\n",
    "# Calculate SMAPE for fcts_tl\n",
    "smape_tl_tourism = calculate_smape(Y_test_df_tourism, predictions_tl_tourism, moe.__class__.__name__)\n",
    "smape_tl_m3 = calculate_smape(Y_test_df_m3, predictions_tl_m3, moe.__class__.__name__)\n",
    "\n",
    "# Print SMAPE values\n",
    "print(f\"SMAPE for fcts_tl_tourism: {smape_tl_tourism}\")\n",
    "print(f\"SMAPE for fcts_tl_m3: {smape_tl_m3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f4d53",
   "metadata": {},
   "source": [
    "predict on other dataset ... \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
