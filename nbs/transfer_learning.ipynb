{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89e25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-16 19:04:13,110\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-04-16 19:04:13,323\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\gluonts\\json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.models import NBEATS\n",
    "from neuralforecast import NeuralForecast\n",
    "from utils import load_dataset, train_test_split\n",
    "from models.NBeatsMoe import NBeatsMoe, NBEATSMoEBlock\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "# datasets list\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"gluonts_tourism_monthly\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"m3\",\n",
    "        \"directory\": \"C:\\\\Users\\\\ricar\\\\mixture_of_experts_time_series\\\\data\\\\m3\\\\\",\n",
    "        \"group\": \"Monthly\",\n",
    "        \"freq\": \"M\",\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b6710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using dataset already processed in path C:\\Users\\ricar\\.gluonts\\datasets\\tourism_monthly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tourism_monthly dataset...\n",
      "Loading m3_monthly dataset...\n"
     ]
    }
   ],
   "source": [
    "Y_ALL_tourism, horizon, n_lags, group, _ = load_dataset(\"gluonts_tourism_monthly\", datasets[0])\n",
    "Y_ALL_m3 = load_dataset(\"m3\", datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af984ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(n_lags)\n",
    "Y_train_df_tourism, Y_test_df_tourism = train_test_split(Y_ALL_tourism, horizon)\n",
    "Y_train_df_m3, Y_test_df_m3 = train_test_split(Y_ALL_m3, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786a3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "models_tourism = NBEATS(h=horizon, input_size=n_lags)\n",
    "models_m3 = NBEATS(h=horizon, input_size=n_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e37352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "1.6 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.853     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:  33%|███▎      | 4/12 [00:00<00:01,  4.39it/s, v_num=44, train_loss_step=1.15e+3, train_loss_epoch=893.0, valid_loss=2.65e+3]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:  33%|███▎      | 4/12 [00:00<00:01,  4.37it/s, v_num=44, train_loss_step=1.15e+3, train_loss_epoch=893.0, valid_loss=2.65e+3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "1.6 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.853     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:02<00:10,  3.48it/s, v_num=45, train_loss_step=488.0, train_loss_epoch=579.0, valid_loss=665.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:02<00:10,  3.47it/s, v_num=45, train_loss_step=488.0, train_loss_epoch=579.0, valid_loss=665.0]\n"
     ]
    }
   ],
   "source": [
    "fcst_tourism = NeuralForecast(models=[models_tourism], freq=\"M\")\n",
    "fcst_tourism.fit(df=Y_train_df_tourism, static_df=None, val_size=horizon)\n",
    "\n",
    "fcst_m3 = NeuralForecast(models=[models_m3], freq=\"M\")\n",
    "fcst_m3.fit(df=Y_train_df_m3, static_df=None, val_size=horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7c061",
   "metadata": {},
   "source": [
    "Now lets add the 2 datasets together ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45eacd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "blcs_tourism = fcst_tourism.models[0].blocks\n",
    "blcs_m3 = fcst_m3.models[0].blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bfc10",
   "metadata": {},
   "source": [
    "... and the 2 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ade93070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): NBEATSMoEBlock(\n",
       "    (experts): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (6): ReLU()\n",
       "        (7): Linear(in_features=512, out_features=42, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gate): Sequential(\n",
       "      (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=24, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (pooling): SparsePooling(\n",
       "      (experts): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (6): ReLU()\n",
       "          (7): Linear(in_features=512, out_features=42, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): Sequential(\n",
       "        (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (basis): IdentityBasis()\n",
       "  )\n",
       "  (1): NBEATSMoEBlock(\n",
       "    (experts): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (6): ReLU()\n",
       "        (7): Linear(in_features=512, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gate): Sequential(\n",
       "      (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=24, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (pooling): SparsePooling(\n",
       "      (experts): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (6): ReLU()\n",
       "          (7): Linear(in_features=512, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): Sequential(\n",
       "        (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (basis): TrendBasis()\n",
       "  )\n",
       "  (2): NBEATSMoEBlock(\n",
       "    (experts): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (6): ReLU()\n",
       "        (7): Linear(in_features=512, out_features=68, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gate): Sequential(\n",
       "      (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=24, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (pooling): SparsePooling(\n",
       "      (experts): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (6): ReLU()\n",
       "          (7): Linear(in_features=512, out_features=68, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): Sequential(\n",
       "        (0): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=24, out_features=2, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (basis): SeasonalityBasis()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_layers = nn.ModuleList()\n",
    "\n",
    "for i in zip(blcs_tourism, blcs_m3):\n",
    "    blc1, blc2 = i\n",
    "    added_layers.append(NBEATSMoEBlock(\n",
    "        input_size=n_lags,\n",
    "        top_k=1,\n",
    "        nr_experts=2,\n",
    "        n_theta=1,\n",
    "        mlp_units=[[16,16], [16,16], [16,16]], ## just moked\n",
    "        basis=blc1.basis,\n",
    "        activation=\"ReLU\",\n",
    "        dropout_prob=blc1.dropout_prob,\n",
    "        pre_experts=nn.ModuleList([blc1.layers, blc2.layers]),\n",
    "    ))\n",
    "added_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "moe = NBeatsMoe(\n",
    "    pre_blocks=added_layers,\n",
    "    nr_experts=2,\n",
    "    top_k=1,\n",
    "    input_size=n_lags,\n",
    "    h=horizon,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a23d1",
   "metadata": {},
   "source": [
    "Let's train ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8469a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID0</td>\n",
       "      <td>1979-01-31</td>\n",
       "      <td>1149.869995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID0</td>\n",
       "      <td>1979-02-28</td>\n",
       "      <td>1053.800171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID0</td>\n",
       "      <td>1979-03-31</td>\n",
       "      <td>1388.879761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID0</td>\n",
       "      <td>1979-04-30</td>\n",
       "      <td>1783.370239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID0</td>\n",
       "      <td>1979-05-31</td>\n",
       "      <td>1921.025146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268053</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-10-31</td>\n",
       "      <td>5225.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268054</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-11-30</td>\n",
       "      <td>5236.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268055</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-12-31</td>\n",
       "      <td>5186.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268056</th>\n",
       "      <td>M999</td>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>5143.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268057</th>\n",
       "      <td>M999</td>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>5152.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268058 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id         ds            y\n",
       "0            ID0 1979-01-31  1149.869995\n",
       "1            ID0 1979-02-28  1053.800171\n",
       "2            ID0 1979-03-31  1388.879761\n",
       "3            ID0 1979-04-30  1783.370239\n",
       "4            ID0 1979-05-31  1921.025146\n",
       "...          ...        ...          ...\n",
       "268053      M999 1993-10-31  5225.900000\n",
       "268054      M999 1993-11-30  5236.300000\n",
       "268055      M999 1993-12-31  5186.600000\n",
       "268056      M999 1994-01-31  5143.400000\n",
       "268057      M999 1994-02-28  5152.600000\n",
       "\n",
       "[268058 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add both y_all\n",
    "Y_ALL = Y_ALL_tourism.copy()\n",
    "Y_ALL = pd.concat([Y_ALL, Y_ALL_m3], ignore_index=True)\n",
    "\n",
    "# split train and test\n",
    "Y_train_df, Y_test_df = train_test_split(Y_ALL, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6165b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 348 K  | train\n",
      "-------------------------------------------------------\n",
      "346 K     Trainable params\n",
      "1.6 K     Non-trainable params\n",
      "348 K     Total params\n",
      "1.393     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  54%|█████▍    | 31/57 [00:04<00:04,  6.49it/s, v_num=52, train_loss_step=1.27e+3, train_loss_epoch=769.0, valid_loss=1.08e+3] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  54%|█████▍    | 31/57 [00:04<00:04,  6.49it/s, v_num=52, train_loss_step=1.27e+3, train_loss_epoch=769.0, valid_loss=1.08e+3]\n"
     ]
    }
   ],
   "source": [
    "fcts_tl = NeuralForecast(models=[moe], freq=\"M\")\n",
    "fcts_tl.fit(df=Y_train_df, static_df=None, val_size=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61dc4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 57/57 [00:01<00:00, 36.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 45/45 [00:00<00:00, 66.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# lets predict ...\n",
    "predictions = fcts_tl.predict(futr_df=Y_test_df)\n",
    "predictions_tourism = fcst_tourism.predict(futr_df=Y_test_df_tourism)\n",
    "predictions_m3 = fcst_m3.predict(futr_df=Y_test_df_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e12deffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl: 0.16832611697917035\n",
      "SMAPE for fcst_tourism: 0.24402993926027292\n",
      "SMAPE for fcst_m3: 0.13870548088695284\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.losses.numpy import smape\n",
    "\n",
    "# Calculate SMAPE for each prediction\n",
    "\n",
    "# For predictions from fcts_tl\n",
    "def calculate_smape(Y_test, predictions, model_name):\n",
    "    y_true = Y_test['y'].values\n",
    "    y_hat = predictions[model_name].values\n",
    "\n",
    "    n_series = Y_test['unique_id'].nunique()\n",
    "    y_true = y_true.reshape(n_series, -1)\n",
    "    y_hat = y_hat.reshape(n_series, -1)\n",
    "\n",
    "    smape_value = smape(y_true, y_hat)\n",
    "    return smape_value\n",
    "\n",
    "# Calculate SMAPE for fcts_tl\n",
    "smape_tl = calculate_smape(Y_test_df, predictions, moe.__class__.__name__)\n",
    "smape_tourism = calculate_smape(Y_test_df_tourism, predictions_tourism, \"NBEATS\")\n",
    "smape_m3 = calculate_smape(Y_test_df_m3, predictions_m3, \"NBEATS\")\n",
    "\n",
    "# Print SMAPE values\n",
    "print(f\"SMAPE for fcts_tl: {smape_tl}\")\n",
    "print(f\"SMAPE for fcst_tourism: {smape_tourism}\")\n",
    "print(f\"SMAPE for fcst_m3: {smape_m3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d989320",
   "metadata": {},
   "source": [
    "Test the moe on both datasets independently ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92f37fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl_tourism: 0.24736914875104038\n",
      "SMAPE for fcts_tl_m3: 0.1480671886678927\n"
     ]
    }
   ],
   "source": [
    "predictions_tl_tourism = predictions[~predictions['unique_id'].str.match(r'^M\\d+')]\n",
    "predictions_tl_m3 = predictions[predictions['unique_id'].str.match(r'^M\\d+')]\n",
    "\n",
    "# Calculate SMAPE for fcts_tl\n",
    "smape_tl_tourism = calculate_smape(Y_test_df_tourism, predictions_tl_tourism, moe.__class__.__name__)\n",
    "smape_tl_m3 = calculate_smape(Y_test_df_m3, predictions_tl_m3, moe.__class__.__name__)\n",
    "\n",
    "# Print SMAPE values\n",
    "print(f\"SMAPE for fcts_tl_tourism: {smape_tl_tourism}\")\n",
    "print(f\"SMAPE for fcts_tl_m3: {smape_tl_m3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f4d53",
   "metadata": {},
   "source": [
    "predict on other dataset ... \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
