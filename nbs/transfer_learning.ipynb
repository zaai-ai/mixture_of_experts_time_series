{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89e25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c9a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-21 15:16:02,120\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-04-21 15:16:03,112\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.models import NBEATS\n",
    "from neuralforecast import NeuralForecast\n",
    "from utils import load_dataset, train_test_split\n",
    "from models.NBeatsMoe import NBeatsMoe, NBEATSMoEBlock\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "# datasets list\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"gluonts_tourism_monthly\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"m3\",\n",
    "        \"directory\": \"/home/ricardo/mixture_of_experts_time_series/data/m3/\",\n",
    "        \"group\": \"Monthly\",\n",
    "        \"freq\": \"M\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"m4\",\n",
    "        \"directory\": \"/home/ricardo/mixture_of_experts_time_series/data/m4/\",\n",
    "        \"group\": \"Monthly\",\n",
    "        \"freq\": \"M\",\n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b6710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading m4_monthly dataset...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Y_ALL_m4 = load_dataset(\"m4\", datasets[2])\n",
    "Y_ALL_m3 = load_dataset(\"m3\", datasets[1])\n",
    "n_lags = 36\n",
    "horizon = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>8350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-03-31</td>\n",
       "      <td>8570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-04-30</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-05-31</td>\n",
       "      <td>7080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246406</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2000-11-30</td>\n",
       "      <td>4200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246407</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>4300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246408</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246409</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246410</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>4300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11246411 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id         ds       y\n",
       "0              4M1 1994-01-31  8000.0\n",
       "1              4M1 1994-02-28  8350.0\n",
       "2              4M1 1994-03-31  8570.0\n",
       "3              4M1 1994-04-30  7700.0\n",
       "4              4M1 1994-05-31  7080.0\n",
       "...            ...        ...     ...\n",
       "11246406    4M9999 2000-11-30  4200.0\n",
       "11246407    4M9999 2000-12-31  4300.0\n",
       "11246408    4M9999 2001-01-31  3800.0\n",
       "11246409    4M9999 2001-02-28  4400.0\n",
       "11246410    4M9999 2001-03-31  4300.0\n",
       "\n",
       "[11246411 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "start_date = pd.to_datetime('1994-01-31')\n",
    "\n",
    "def convert_to_date(group):\n",
    "    group = group.copy()\n",
    "    periods = len(group)\n",
    "    group['unique_id'] = \"4\" + group['unique_id']\n",
    "    group['ds'] = pd.date_range(start=start_date, periods=periods, freq='M')\n",
    "    return group\n",
    "\n",
    "Y_ALL_m4 = Y_ALL_m4.groupby('unique_id', group_keys=False).apply(convert_to_date)\n",
    "Y_ALL_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af984ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(n_lags)\n",
    "Y_train_df_m4, Y_test_df_m4 = train_test_split(Y_ALL_m4, horizon)\n",
    "Y_train_df_m3, Y_test_df_m3 = train_test_split(Y_ALL_m3, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "models_m4 = NBEATS(h=horizon, input_size=n_lags, max_steps=1500)\n",
    "models_m3 = NBEATS(h=horizon, input_size=n_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e37352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "2.0 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.954     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1500/1500 [05:17<00:00,  4.73it/s, v_num=117, train_loss_step=444.0, valid_loss=506.0, train_loss_epoch=389.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1500/1500 [05:17<00:00,  4.73it/s, v_num=117, train_loss_step=444.0, valid_loss=506.0, train_loss_epoch=389.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "2.0 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.954     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:00<00:03, 11.05it/s, v_num=118, train_loss_step=450.0, train_loss_epoch=561.0, valid_loss=661.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 10/45 [00:00<00:03, 11.02it/s, v_num=118, train_loss_step=450.0, train_loss_epoch=561.0, valid_loss=661.0]\n"
     ]
    }
   ],
   "source": [
    "fcst_m4 = NeuralForecast(models=[models_m4], freq=\"M\")\n",
    "fcst_m4.fit(df=Y_train_df_m4, static_df=None, val_size=horizon)\n",
    "\n",
    "fcst_m3 = NeuralForecast(models=[models_m3], freq=\"M\")\n",
    "fcst_m3.fit(df=Y_train_df_m3, static_df=None, val_size=horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7c061",
   "metadata": {},
   "source": [
    "Now lets add the 2 datasets together ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eacd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "blcs_m4 = fcst_m4.models[0].blocks\n",
    "blcs_m3 = fcst_m3.models[0].blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bfc10",
   "metadata": {},
   "source": [
    "... and the 2 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade93070",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_layers = nn.ModuleList()\n",
    "for i in zip(blcs_m4, blcs_m3):\n",
    "    blc1, blc2 = i\n",
    "    n_theta = blc1.layers[-1].out_features\n",
    "\n",
    "    #freeze training layers\n",
    "    for param in blc1.layers.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in blc2.layers.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    added_layers.append(NBEATSMoEBlock(\n",
    "        input_size=n_lags,\n",
    "        top_k=1,\n",
    "        nr_experts=2,\n",
    "        n_theta=n_theta,\n",
    "        mlp_units=[[16,16], [16,16], [16,16]], ## just mocked\n",
    "        basis=blc1.basis,\n",
    "        activation=\"ReLU\",\n",
    "        dropout_prob=blc1.dropout_prob,\n",
    "        pre_experts=nn.ModuleList([blc1.layers, blc2.layers]),\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "moe = NBeatsMoe(\n",
    "    pre_blocks=added_layers,\n",
    "    nr_experts=2,\n",
    "    top_k=2, # TODO: try changing this to 2\n",
    "    input_size=n_lags,\n",
    "    h=horizon,\n",
    "    learning_rate=1e-5,\n",
    "    max_steps=1500,\n",
    "    gate_type=\"conv1d-gap\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a23d1",
   "metadata": {},
   "source": [
    "Let's train ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add both y_all\n",
    "Y_ALL = Y_ALL_m4.copy()\n",
    "Y_ALL = pd.concat([Y_ALL, Y_ALL_m3], ignore_index=True)\n",
    "\n",
    "# split train and test\n",
    "Y_train_df, Y_test_df = train_test_split(Y_ALL, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6165b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 5.0 M  | train\n",
      "-------------------------------------------------------\n",
      "438       Trainable params\n",
      "5.0 M     Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.901    Total estimated model params size (MB)\n",
      "76        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|█████████▋| 1500/1545 [07:56<00:14,  3.15it/s, v_num=119, train_loss_step=294.0, valid_loss=532.0, train_loss_epoch=393.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|█████████▋| 1500/1545 [07:56<00:14,  3.15it/s, v_num=119, train_loss_step=294.0, valid_loss=532.0, train_loss_epoch=393.0]\n"
     ]
    }
   ],
   "source": [
    "fcts_tl = NeuralForecast(models=[moe], freq=\"M\")\n",
    "fcts_tl.fit(df=Y_train_df, static_df=None, val_size=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1545/1545 [00:20<00:00, 75.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1500/1500 [00:11<00:00, 134.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 45/45 [00:00<00:00, 159.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# lets predict ...\n",
    "predictions = fcts_tl.predict(futr_df=Y_test_df)\n",
    "predictions_m4 = fcst_m4.predict(futr_df=Y_test_df_m4)\n",
    "predictions_m3 = fcst_m3.predict(futr_df=Y_test_df_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12deffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl: 0.13325057937633744\n",
      "SMAPE for fcst_m4: 0.1278452707465983\n",
      "SMAPE for fcst_m3: 0.13939638798222523\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.losses.numpy import smape\n",
    "\n",
    "# Calculate SMAPE for each prediction\n",
    "\n",
    "# For predictions from fcts_tl\n",
    "def calculate_smape(Y_test, predictions, model_name):\n",
    "    y_true = Y_test['y'].values\n",
    "    y_hat = predictions[model_name].values\n",
    "\n",
    "    n_series = Y_test['unique_id'].nunique()\n",
    "    y_true = y_true.reshape(n_series, -1)\n",
    "    y_hat = y_hat.reshape(n_series, -1)\n",
    "\n",
    "    smape_value = smape(y_true, y_hat)\n",
    "    return smape_value\n",
    "\n",
    "# Calculate SMAPE for fcts_tl\n",
    "smape_tl = calculate_smape(Y_test_df, predictions, moe.__class__.__name__)\n",
    "smape_m4 = calculate_smape(Y_test_df_m4, predictions_m4, \"NBEATS\")\n",
    "smape_m3 = calculate_smape(Y_test_df_m3, predictions_m3, \"NBEATS\")\n",
    "\n",
    "# Print SMAPE values\n",
    "print(f\"SMAPE for fcts_tl: {smape_tl}\")\n",
    "print(f\"SMAPE for fcst_m4: {smape_m4}\")\n",
    "print(f\"SMAPE for fcst_m3: {smape_m3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20ce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-03-31</td>\n",
       "      <td>2280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-04-30</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-05-31</td>\n",
       "      <td>5040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-06-30</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-07-31</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-10-31</td>\n",
       "      <td>5225.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25700</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-11-30</td>\n",
       "      <td>5236.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25701</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-12-31</td>\n",
       "      <td>5186.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25702</th>\n",
       "      <td>M999</td>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>5143.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25703</th>\n",
       "      <td>M999</td>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>5152.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25704 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id         ds       y\n",
       "0            M1 1994-03-31  2280.0\n",
       "1            M1 1994-04-30   480.0\n",
       "2            M1 1994-05-31  5040.0\n",
       "3            M1 1994-06-30  1920.0\n",
       "4            M1 1994-07-31   840.0\n",
       "...         ...        ...     ...\n",
       "25699      M999 1993-10-31  5225.9\n",
       "25700      M999 1993-11-30  5236.3\n",
       "25701      M999 1993-12-31  5186.6\n",
       "25702      M999 1994-01-31  5143.4\n",
       "25703      M999 1994-02-28  5152.6\n",
       "\n",
       "[25704 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_df_m3 # TODO: change the name of the unique ids for the m3 or m4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d989320",
   "metadata": {},
   "source": [
    "Test the moe on both datasets independently ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f37fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl_m4: 0.13296226673629807\n",
      "SMAPE for fcts_tl_m3: 0.14294176055413135\n"
     ]
    }
   ],
   "source": [
    "predictions_tl_m4 = predictions[~predictions['unique_id'].str.match(r'^M\\d+')]\n",
    "predictions_tl_m3 = predictions[predictions['unique_id'].str.match(r'^M\\d+')]\n",
    "\n",
    "# Calculate SMAPE for fcts_tl\n",
    "smape_tl_m4 = calculate_smape(Y_test_df_m4, predictions_tl_m4, moe.__class__.__name__)\n",
    "smape_tl_m3 = calculate_smape(Y_test_df_m3, predictions_tl_m3, moe.__class__.__name__)\n",
    "\n",
    "# Print SMAPE values\n",
    "print(f\"SMAPE for fcts_tl_m4: {smape_tl_m4}\")\n",
    "print(f\"SMAPE for fcts_tl_m3: {smape_tl_m3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f4d53",
   "metadata": {},
   "source": [
    "predict on other dataset ... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6776e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using dataset already processed in path C:\\Users\\ricar\\.gluonts\\datasets\\tourism_monthly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tourism_monthly dataset...\n"
     ]
    }
   ],
   "source": [
    "Y_ALL_tourism = load_dataset(\"gluonts_tourism_monthly\", datasets[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df_tourism, Y_test_df_tourism = train_test_split(Y_ALL_tourism, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957de09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 65.27it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_tourism = fcts_tl.predict(df=Y_train_df_tourism,futr_df=Y_test_df_tourism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec947b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl_tourism: 0.2652475786814189\n"
     ]
    }
   ],
   "source": [
    "smape_tl_tourism = calculate_smape(Y_test_df_tourism, predictions_tourism, moe.__class__.__name__)\n",
    "\n",
    "print(f\"SMAPE for fcts_tl_tourism: {smape_tl_tourism}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
