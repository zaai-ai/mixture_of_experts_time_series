{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89e25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c9a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-17 02:41:20,157\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-04-17 02:41:20,336\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "c:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\gluonts\\json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.models import NBEATS\n",
    "from neuralforecast import NeuralForecast\n",
    "from utils import load_dataset, train_test_split\n",
    "from models.NBeatsMoe import NBeatsMoe, NBEATSMoEBlock\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "# datasets list\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"gluonts_tourism_monthly\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"m3\",\n",
    "        \"directory\": \"C:\\\\Users\\\\ricar\\\\mixture_of_experts_time_series\\\\data\\\\m3\\\\\",\n",
    "        \"group\": \"Monthly\",\n",
    "        \"freq\": \"M\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"m4\",\n",
    "        \"directory\": \"C:\\\\Users\\\\ricar\\\\mixture_of_experts_time_series\\\\data\\\\m4\\\\\",\n",
    "        \"group\": \"Monthly\",\n",
    "        \"freq\": \"M\",\n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b6710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading m4_monthly dataset...\n",
      "Loading m3_monthly dataset...\n"
     ]
    }
   ],
   "source": [
    "Y_ALL_m4 = load_dataset(\"m4\", datasets[2])\n",
    "Y_ALL_m3 = load_dataset(\"m3\", datasets[1])\n",
    "n_lags = 36\n",
    "horizon = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40fd9570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  13%|█▎        | 200/1500 [26:39<2:53:14,  0.13it/s, v_num=87, train_loss_step=445.0, valid_loss=531.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>8350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-03-31</td>\n",
       "      <td>8570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-04-30</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4M1</td>\n",
       "      <td>1994-05-31</td>\n",
       "      <td>7080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246406</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2000-11-30</td>\n",
       "      <td>4200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246407</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>4300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246408</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246409</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246410</th>\n",
       "      <td>4M9999</td>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>4300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11246411 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id         ds       y\n",
       "0              4M1 1994-01-31  8000.0\n",
       "1              4M1 1994-02-28  8350.0\n",
       "2              4M1 1994-03-31  8570.0\n",
       "3              4M1 1994-04-30  7700.0\n",
       "4              4M1 1994-05-31  7080.0\n",
       "...            ...        ...     ...\n",
       "11246406    4M9999 2000-11-30  4200.0\n",
       "11246407    4M9999 2000-12-31  4300.0\n",
       "11246408    4M9999 2001-01-31  3800.0\n",
       "11246409    4M9999 2001-02-28  4400.0\n",
       "11246410    4M9999 2001-03-31  4300.0\n",
       "\n",
       "[11246411 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "start_date = pd.to_datetime('1994-01-31')\n",
    "\n",
    "def convert_to_date(group):\n",
    "    group = group.copy()\n",
    "    periods = len(group)\n",
    "    group['unique_id'] = \"4\" + group['unique_id']\n",
    "    group['ds'] = pd.date_range(start=start_date, periods=periods, freq='M')\n",
    "    return group\n",
    "\n",
    "Y_ALL_m4 = Y_ALL_m4.groupby('unique_id', group_keys=False).apply(convert_to_date)\n",
    "Y_ALL_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af984ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(n_lags)\n",
    "Y_train_df_m4, Y_test_df_m4 = train_test_split(Y_ALL_m4, horizon)\n",
    "Y_train_df_m3, Y_test_df_m3 = train_test_split(Y_ALL_m3, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "786a3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "models_m4 = NBEATS(h=horizon, input_size=n_lags)\n",
    "models_m3 = NBEATS(h=horizon, input_size=n_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e37352",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_m4 = NeuralForecast(models=[models_m4], freq=\"M\")\n",
    "fcst_m4.fit(df=Y_train_df_m4, static_df=None, val_size=horizon)\n",
    "\n",
    "fcst_m3 = NeuralForecast(models=[models_m3], freq=\"M\")\n",
    "fcst_m3.fit(df=Y_train_df_m3, static_df=None, val_size=horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7c061",
   "metadata": {},
   "source": [
    "Now lets add the 2 datasets together ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eacd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "blcs_m4 = fcst_m4.models[0].blocks\n",
    "blcs_m3 = fcst_m3.models[0].blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bfc10",
   "metadata": {},
   "source": [
    "... and the 2 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade93070",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_layers = nn.ModuleList()\n",
    "for i in zip(blcs_m4, blcs_m3):\n",
    "    blc1, blc2 = i\n",
    "    n_theta = blc1.layers[-1].out_features\n",
    "\n",
    "    #freeze training layers\n",
    "    for param in blc1.layers.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in blc2.layers.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    added_layers.append(NBEATSMoEBlock(\n",
    "        input_size=n_lags,\n",
    "        top_k=1,\n",
    "        nr_experts=2,\n",
    "        n_theta=n_theta,\n",
    "        mlp_units=[[16,16], [16,16], [16,16]], ## just mocked\n",
    "        basis=blc1.basis,\n",
    "        activation=\"ReLU\",\n",
    "        dropout_prob=blc1.dropout_prob,\n",
    "        pre_experts=nn.ModuleList([blc1.layers, blc2.layers]),\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "moe = NBeatsMoe(\n",
    "    pre_blocks=added_layers,\n",
    "    nr_experts=2,\n",
    "    top_k=1,\n",
    "    input_size=n_lags,\n",
    "    h=horizon,\n",
    "    # learning_rate=1e-5,\n",
    "    # max_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a23d1",
   "metadata": {},
   "source": [
    "Let's train ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add both y_all\n",
    "Y_ALL = Y_ALL_m4.copy()\n",
    "Y_ALL = pd.concat([Y_ALL, Y_ALL_m3], ignore_index=True)\n",
    "\n",
    "# split train and test\n",
    "Y_train_df, Y_test_df = train_test_split(Y_ALL, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6165b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 5.0 M  | train\n",
      "-------------------------------------------------------\n",
      "438       Trainable params\n",
      "5.0 M     Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.901    Total estimated model params size (MB)\n",
      "76        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|██████▋   | 1000/1500 [12:46<06:23,  1.30it/s, v_num=88, train_loss_step=441.0, valid_loss=531.0, train_loss_epoch=402.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|██████▋   | 1000/1500 [12:46<06:23,  1.30it/s, v_num=88, train_loss_step=441.0, valid_loss=531.0, train_loss_epoch=402.0]\n"
     ]
    }
   ],
   "source": [
    "fcts_tl = NeuralForecast(models=[moe], freq=\"M\")\n",
    "fcts_tl.fit(df=Y_train_df, static_df=None, val_size=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1500/1500 [01:12<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1500/1500 [00:26<00:00, 56.01it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 45/45 [00:00<00:00, 71.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# lets predict ...\n",
    "predictions = fcts_tl.predict(futr_df=Y_test_df)\n",
    "predictions_m4 = fcst_m4.predict(futr_df=Y_test_df_m4)\n",
    "predictions_m3 = fcst_m3.predict(futr_df=Y_test_df_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12deffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl: 0.13306470799170056\n",
      "SMAPE for fcst_m4: 0.12900698340481298\n",
      "SMAPE for fcst_m3: 0.13939638798222523\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.losses.numpy import smape\n",
    "\n",
    "# Calculate SMAPE for each prediction\n",
    "\n",
    "# For predictions from fcts_tl\n",
    "def calculate_smape(Y_test, predictions, model_name):\n",
    "    y_true = Y_test['y'].values\n",
    "    y_hat = predictions[model_name].values\n",
    "\n",
    "    n_series = Y_test['unique_id'].nunique()\n",
    "    y_true = y_true.reshape(n_series, -1)\n",
    "    y_hat = y_hat.reshape(n_series, -1)\n",
    "\n",
    "    smape_value = smape(y_true, y_hat)\n",
    "    return smape_value\n",
    "\n",
    "# Calculate SMAPE for fcts_tl\n",
    "smape_tl = calculate_smape(Y_test_df, predictions, moe.__class__.__name__)\n",
    "smape_m4 = calculate_smape(Y_test_df_m4, predictions_m4, \"NBEATS\")\n",
    "smape_m3 = calculate_smape(Y_test_df_m3, predictions_m3, \"NBEATS\")\n",
    "\n",
    "# Print SMAPE values\n",
    "print(f\"SMAPE for fcts_tl: {smape_tl}\")\n",
    "print(f\"SMAPE for fcst_m4: {smape_m4}\")\n",
    "print(f\"SMAPE for fcst_m3: {smape_m3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20ce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-03-31</td>\n",
       "      <td>2280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-04-30</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-05-31</td>\n",
       "      <td>5040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-06-30</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M1</td>\n",
       "      <td>1994-07-31</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-10-31</td>\n",
       "      <td>5225.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25700</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-11-30</td>\n",
       "      <td>5236.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25701</th>\n",
       "      <td>M999</td>\n",
       "      <td>1993-12-31</td>\n",
       "      <td>5186.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25702</th>\n",
       "      <td>M999</td>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>5143.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25703</th>\n",
       "      <td>M999</td>\n",
       "      <td>1994-02-28</td>\n",
       "      <td>5152.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25704 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id         ds       y\n",
       "0            M1 1994-03-31  2280.0\n",
       "1            M1 1994-04-30   480.0\n",
       "2            M1 1994-05-31  5040.0\n",
       "3            M1 1994-06-30  1920.0\n",
       "4            M1 1994-07-31   840.0\n",
       "...         ...        ...     ...\n",
       "25699      M999 1993-10-31  5225.9\n",
       "25700      M999 1993-11-30  5236.3\n",
       "25701      M999 1993-12-31  5186.6\n",
       "25702      M999 1994-01-31  5143.4\n",
       "25703      M999 1994-02-28  5152.6\n",
       "\n",
       "[25704 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_df_m3 # TODO: change the name of the unique ids for the m3 or m4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d989320",
   "metadata": {},
   "source": [
    "Test the moe on both datasets independently ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f37fbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (48000,18) (48000,0) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m predictions_tl_m3 \u001b[38;5;241m=\u001b[39m predictions[predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^M\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate SMAPE for fcts_tl\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m smape_tl_m4 \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_smape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test_df_m4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_tl_m4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m smape_tl_m3 \u001b[38;5;241m=\u001b[39m calculate_smape(Y_test_df_m3, predictions_tl_m3, moe\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print SMAPE values\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 14\u001b[0m, in \u001b[0;36mcalculate_smape\u001b[1;34m(Y_test, predictions, model_name)\u001b[0m\n\u001b[0;32m     11\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape(n_series, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m y_hat\u001b[38;5;241m.\u001b[39mreshape(n_series, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m smape_value \u001b[38;5;241m=\u001b[39m \u001b[43msmape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m smape_value\n",
      "File \u001b[1;32mc:\\Users\\ricar\\mixture_of_experts_time_series\\venv\\Lib\\site-packages\\neuralforecast\\losses\\numpy.py:207\u001b[0m, in \u001b[0;36msmape\u001b[1;34m(y, y_hat, weights, axis)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Symmetric Mean Absolute Percentage Error\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03mCalculates Symmetric Mean Absolute Percentage Error between\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m[Makridakis S., \"Accuracy measures: theoretical and practical concerns\".](https://www.sciencedirect.com/science/article/pii/0169207093900793)\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m _metric_protections(y, y_hat, weights)\n\u001b[1;32m--> 207\u001b[0m delta_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m)\n\u001b[0;32m    208\u001b[0m scale \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(y) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(y_hat)\n\u001b[0;32m    209\u001b[0m smape \u001b[38;5;241m=\u001b[39m _divide_no_nan(delta_y, scale)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (48000,18) (48000,0) "
     ]
    }
   ],
   "source": [
    "predictions_tl_m4 = predictions[~predictions['unique_id'].str.match(r'^M\\d+')]\n",
    "predictions_tl_m3 = predictions[predictions['unique_id'].str.match(r'^M\\d+')]\n",
    "\n",
    "# Calculate SMAPE for fcts_tl\n",
    "smape_tl_m4 = calculate_smape(Y_test_df_m4, predictions_tl_m4, moe.__class__.__name__)\n",
    "smape_tl_m3 = calculate_smape(Y_test_df_m3, predictions_tl_m3, moe.__class__.__name__)\n",
    "\n",
    "# Print SMAPE values\n",
    "print(f\"SMAPE for fcts_tl_m4: {smape_tl_m4}\")\n",
    "print(f\"SMAPE for fcts_tl_m3: {smape_tl_m3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f4d53",
   "metadata": {},
   "source": [
    "predict on other dataset ... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6776e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using dataset already processed in path C:\\Users\\ricar\\.gluonts\\datasets\\tourism_monthly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tourism_monthly dataset...\n"
     ]
    }
   ],
   "source": [
    "Y_ALL_tourism = load_dataset(\"gluonts_tourism_monthly\", datasets[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df_tourism, Y_test_df_tourism = train_test_split(Y_ALL_tourism, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957de09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 23.82it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_tourism = fcts_tl.predict(df=Y_train_df_tourism,futr_df=Y_test_df_tourism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec947b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for fcts_tl_tourism: 0.26907674114804797\n"
     ]
    }
   ],
   "source": [
    "smape_tl_tourism = calculate_smape(Y_test_df_tourism, predictions_tourism, moe.__class__.__name__)\n",
    "\n",
    "print(f\"SMAPE for fcts_tl_tourism: {smape_tl_tourism}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
